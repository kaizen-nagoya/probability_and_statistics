2019年、俺の読んだ論文50本全部解説(俺的ベスト3付き) 綿岡晃輝
https://qiita.com/wataoka/items/ae782defabc3706b5c93

深層学習五十論文 by 綿岡晃輝 単語帳(shell, awk), 英語(25) docker(101)
https://qiita.com/kaizen_nagoya/items/670d4d332e07fd2e5fc2

https://hub.docker.com/u/kaizenjapan
$ docker run -v /tmp/docker:/tmp/docker -it kaizenjapan/qc-nakamori /bin/bash

# 1 A Survey on Bias and Fairness in Machine Learning

BMI

Correctional Offender Management Profiling for Alternative Sanctions (COMPAS)
Defense Advanced Research Projects Agency (DARPA)
Diversity in Faces (DiF) 
Equal Credit Opportunity Acts (ECOA)
Fair Housing Acts(FHA)
labeled faces in the wild (LFW)
maximum mean discrepancy (MMD)
price of fairness (POF)
reducing bias amplification (RBA)
Sentence Encoder Association Test (SEAT)
Science, Technology, Engineering, and Math (STEM)
Variational Auto Encoders(VAE)
Word Embedding Association Test (WEAT)



REFERENCES

[1] Alekh Agarwal, Miroslav Dudik, and Zhiwei Steven Wu. 2019. Fair Regression: Quantitative Definitions and Reduction- Based Algorithms. In International Conference on Machine Learning. 120–129.

[2] Nazanin Alipourfard, Peter G Fennell, and Kristina Lerman. 2018. Can you Trust the Trend?: Discovering Simpson’s Paradoxes in Social Data. In Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining. ACM, 19–27.

[3]NazaninAlipourfard,PeterGFennell,andKristinaLerman.2018.UsingSimpsonâA ̆Z ́sParadoxtoDiscoverInteresting Patterns in Behavioral Data. In Twelfth International AAAI Conference on Web and Social Media.

[4] Alexander Amini, Ava Soleimany, Wilko Schwarting, Sangeeta Bhatia, and Daniela Rus. 2019. Uncovering and Mitigating Algorithmic Bias through Learned Latent Structure. (2019).

[5]JuliaAngwin,JeffLarson,SuryaMattu,andLaurenKirchner.2016.MachineBias:thereâA ̆Z ́ssoftwareusedacrossthe countrytopredictfuturecriminals.AnditâA ̆Z ́sbiasedagainstblacks.ProPublica2016.(2016).

[6] A. Asuncion and D.J. Newman. 2007. UCI Machine Learning Repository. (2007). http://www.ics.uci.edu/$\sim$mlearn/

[7] Arturs Backurs, Piotr Indyk, Krzysztof Onak, Baruch Schieber, Ali Vakilian, and Tal Wagner. 2019. Scalable Fair Clustering. In Proceedings of the 36th International Conference on Machine Learning (Proceedings of Machine Learning Research), Kamalika Chaudhuri and Ruslan Salakhutdinov (Eds.), Vol. 97. PMLR, Long Beach, California, USA, 405–413. http://proceedings.mlr.press/v97/backurs19a.html

[8] Ricardo Baeza-Yates. 2018. Bias on the Web. Commun. ACM 61, 6 (May 2018), 54–61. https://doi.org/10.1145/3209581

[9] Samuel Barbosa, Dan Cosley, Amit Sharma, and Roberto M. Cesar-Jr. 2016. Averaging Gone Wrong: Using Time-Aware Analyses to Better Understand Behavior. (April 2016), 829–841.

[10] Rachel KE Bellamy, Kuntal Dey, Michael Hind, Samuel C Hoffman, Stephanie Houde, Kalapriya Kannan, Pranay Lohia, Jacquelyn Martino, Sameep Mehta, Aleksandra Mojsilovic, et al. 2018. Ai fairness 360: An extensible toolkit for detecting, understanding, and mitigating unwanted algorithmic bias. arXiv preprint arXiv:1810.01943 (2018).

[11] Emily M. Bender and Batya Friedman. 2018. Data Statements for Natural Language Processing: Toward Mitigating System Bias and Enabling Better Science. Transactions of the Association for Computational Linguistics 6 (2018), 587–604. https://doi.org/10.1162/tacl_a_00041

[12] Misha Benjamin, Paul Gagnon, Negar Rostamzadeh, Chris Pal, Yoshua Bengio, and Alex Shee. [n. d.]. TOWARDS
STANDARDIZATION OF DATA LICENSES: THE MONTREAL DATA LICENSE. ([n. d.]).

[13] Richard Berk, Hoda Heidari, Shahin Jabbari, Matthew Joseph, Michael Kearns, Jamie Morgenstern, Seth Neel, and
Aaron Roth. 2017. A Convex Framework for Fair Regression. (2017). arXiv:cs.LG/1706.02409

[14] Richard Berk, Hoda Heidari, Shahin Jabbari, Michael Kearns, and Aaron Roth. [n. d.]. Fairness in criminal justice risk
assessments: The state of the art. Sociological Methods & Research ([n. d.]), 0049124118782533.

[15] Peter J Bickel, Eugene A Hammel, and J William O’Connell. 1975. Sex bias in graduate admissions: Data from Berkeley.
Science 187, 4175 (1975), 398–404.

[16] RDP Binns. 2018. Fairness in machine learning: Lessons from political philosophy. Journal of Machine Learning
Research (2018).

[17] Colin R Blyth. 1972. On Simpson’s paradox and the sure-thing principle. J. Amer. Statist. Assoc. 67, 338 (1972),
364–366.

[18] Miranda Bogen and Aaron Rieke. 2018. Help wanted: an examination of hiring algorithms, equity. Technical Report.
and bias. Technical report, Upturn.

[19] Tolga Bolukbasi, Kai-Wei Chang, James Y Zou, Venkatesh Saligrama, and Adam T Kalai. 2016. Man is to computer programmer as woman is to homemaker? debiasing word embeddings. In Advances in neural information processing systems. 4349–4357.

[20] Shikha Bordia and Samuel Bowman. 2019. Identifying and Reducing Gender Bias in Word-Level Language Models. In
Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics:
Student Research Workshop. 7–15.

[21] Avishek Bose and William Hamilton. 2019. Compositional Fairness Constraints for Graph Embeddings. In International
Conference on Machine Learning. 715–724.

[22] Marc-Etienne Brunet, Colleen Alkalay-Houlihan, Ashton Anderson, and Richard Zemel. 2019. Understanding the Origins of Bias in Word Embeddings. In Proceedings of the 36th International Conference on Machine Learning (Proceedings of Machine Learning Research), Kamalika Chaudhuri and Ruslan Salakhutdinov (Eds.), Vol. 97. PMLR, Long Beach, California, USA, 803–811. http://proceedings.mlr.press/v97/brunet19a.html

[23] Joy Buolamwini and Timnit Gebru. 2018. Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification. In Proceedings of the 1st Conference on Fairness, Accountability and Transparency (Proceedings of Machine Learning Research), Sorelle A. Friedler and Christo Wilson (Eds.), Vol. 81. PMLR, New York, NY, USA, 77–91. http://proceedings.mlr.press/v81/buolamwini18a.html

[24] Toon Calders and Sicco Verwer. 2010. Three naive Bayes approaches for discrimination-free classification. Data Mining and Knowledge Discovery 21, 2 (2010), 277–292.

[25] Aylin Caliskan, Joanna J Bryson, and Arvind Narayanan. 2017. Semantics derived automatically from language corpora contain human-like biases. Science 356, 6334 (2017), 183–186.

[26] Flavio Calmon, Dennis Wei, Bhanukiran Vinzamuri, Karthikeyan Natesan Ramamurthy, and Kush R Varshney. 2017. Optimized Pre-Processing for Discrimination Prevention. In Advances in Neural Information Processing Systems 30, I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (Eds.). Curran Associates, Inc., 3992–4001. http://papers.nips.cc/paper/6988-optimized-pre-processing-for-discrimination-prevention.pdf

[27] Manel Capdevila, Marta Ferrer, and Eulália Luque. 2005. La reincidencia en el delito en la justicia de menores. Centro de estudios jurídicos y formación especializada, Generalitat de Catalunya. Documento no publicado (2005).

[28] Allison JB Chaney, Brandon M Stewart, and Barbara E Engelhardt. 2018. How algorithmic confounding in recommenda- tion systems increases homogeneity and decreases utility. In Proceedings of the 12th ACM Conference on Recommender Systems. ACM, 224–232.

[29] Jiahao Chen, Nathan Kallus, Xiaojie Mao, Geoffry Svacha, and Madeleine Udell. 2019. Fairness Under Unawareness: Assessing Disparity When Protected Class Is Unobserved. In Proceedings of the Conference on Fairness, Accountability, and Transparency. ACM, 339–348.

[30] Xingyu Chen, Brandon Fain, Liang Lyu, and Kamesh Munagala. 2019. Proportionally Fair Clustering. In International Conference on Machine Learning. 1032–1041.

[31] Alexandra Chouldechova. 2017. Fair prediction with disparate impact: A study of bias in recidivism prediction instruments. Big data 5, 2 (2017), 153–163.

[32] Alexandra Chouldechova, Diana Benavides-Prado, Oleksandr Fialko, and Rhema Vaithianathan. 2018. A case study of algorithm-assisted decision making in child maltreatment hotline screening decisions. In Proceedings of the 1st Conference on Fairness, Accountability and Transparency (Proceedings of Machine Learning Research), Sorelle A. Friedler and Christo Wilson (Eds.), Vol. 81. PMLR, New York, NY, USA, 134–148. http://proceedings.mlr.press/v81/ chouldechova18a.html

[33] Alexandra Chouldechova and Aaron Roth. 2018. The frontiers of fairness in machine learning. arXiv preprint arXiv:1810.08810 (2018).

[34] John S. Chuang, Olivier Rivoire, and Stanislas Leibler. 2009. Simpson’s Paradox in a Synthetic Microbial System. Science 323, 5911 (2009), 272–275. https://doi.org/10.1126/science.1166739 arXiv:https://science.sciencemag.org/content/323/5911/272.full.pdf

[35] Lee Cohen, Zachary C. Lipton, and Yishay Mansour. 2019. Efficient candidate screening under multiple tests and implications for fairness. (2019). arXiv:cs.LG/1905.11361

[36] United States. Equal Employment Opportunity Commission. [n. d.]. EEOC compliance manual. [Washington, D.C.] : U.S. Equal Employment Opportunity Commission, [1992].

[37] Sam Corbett-Davies, Emma Pierson, Avi Feller, Sharad Goel, and Aziz Huq. 2017. Algorithmic decision making and the cost of fairness. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 797–806.

[38] Elliot Creager, David Madras, Joern-Henrik Jacobsen, Marissa Weis, Kevin Swersky, Toniann Pitassi, and Richard Zemel. 2019. Flexibly Fair Representation Learning by Disentanglement. In International Conference on Machine Learning. 1436–1445.

[39] Brian d’Alessandro, Cathy O’Neil, and Tom LaGatta. 2017. Conscientious classification: A data scientist’s guide to discrimination-aware classification. Big data 5, 2 (2017), 120–134.

[40] Shai Danziger, Jonathan Levav, and Liora Avnaim-Pesso. 2011. Extraneous factors in judicial decisions. Proceedings of the National Academy of Sciences 108, 17 (2011), 6889–6892.

[41] Julia Dressel and Hany Farid. 2018. The accuracy, fairness, and limits of predicting recidivism. Science Advances 4, 1 (2018). https://doi.org/10.1126/sciadv.aao5580 arXiv:https://advances.sciencemag.org/content/4/1/eaao5580.full.pdf

[42] Dheeru Dua and Casey Graff. 2017. UCI Machine Learning Repository. (2017). http://archive.ics.uci.edu/ml

[43] Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel. 2012. Fairness Through Awareness. In Proceedings of the 3rd Innovations in Theoretical Computer Science Conference (ITCS ’12). ACM, New York, NY,
USA, 214–226. https://doi.org/10.1145/2090236.2090255

[44] Golnoosh Farnadi, Behrouz Babaki, and Lise Getoor. 2018. Fairness in Relational Domains. In Proceedings of the
2018 AAAI/ACM Conference on AI, Ethics, and Society (AIES ’18). ACM, New York, NY, USA, 108–114. https:
//doi.org/10.1145/3278721.3278733

[45] Joel Escudé Font and Marta R Costa-jussà. 2019. Equalizing Gender Biases in Neural Machine Translation with Word
Embeddings Techniques. arXiv preprint arXiv:1901.03116 (2019).

[46] Batya Friedman and Helen Nissenbaum. 1996. Bias in Computer Systems. ACM Trans. Inf. Syst. 14, 3 (July 1996),
330–347. https://doi.org/10.1145/230538.230561

[47] Anna Fry, Thomas J Littlejohns, Cathie Sudlow, Nicola Doherty, Ligia Adamska, Tim Sprosen, Rory Collins, and
Naomi E Allen. 2017. Comparison of Sociodemographic and Health-Related Characteristics of UK Biobank Participants With Those of the General Population. American Journal of Epidemiology 186, 9 (06 2017), 1026–1034. https: //doi.org/10.1093/aje/kwx246 arXiv:http://oup.prod.sis.lan/aje/article-pdf/186/9/1026/24330720/kwx246.pdf

[48] Timnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman Vaughan, Hanna Wallach, Hal Daumé III, and Kate Crawford. [n. d.]. Datasheets for Datasets. ([n. d.]).

[49] Naman Goel, Mohammad Yaghini, and Boi Faltings. 2018. Non-discriminatory machine learning through convex fairness criteria. In Thirty-Second AAAI Conference on Artificial Intelligence.

[50] Hila Gonen and Yoav Goldberg. 2019. Lipstick on a Pig: Debiasing Methods Cover up Systematic Gender Biases in Word Embeddings But do not Remove Them. arXiv preprint arXiv:1903.03862 (2019).

[51] Sandra González-Bailón, Ning Wang, Alejandro Rivero, Javier Borge-Holthoefer, and Yamir Moreno. 2014. Assessing the bias in samples of large online networks. Social Networks 38 (2014), 16–27.

[52] Susan T Gooden. 2015. Race and social equity: A nervous area of government. Routledge.

[53] Nina Grgic-Hlaca, Muhammad Bilal Zafar, Krishna P Gummadi, and Adrian Weller. 2016. The case for process fairness in learning: Feature selection for fair decision making. In NIPS Symposium on Machine Learning and the Law, Vol. 1. 2.

[54] S. Hajian and J. Domingo-Ferrer. 2013. A Methodology for Direct and Indirect Discrimination Prevention in Data
Mining. IEEE Transactions on Knowledge and Data Engineering 25, 7 (July 2013), 1445–1459. https://doi.org/10.
1109/TKDE.2012.72

[55] Moritz Hardt, Eric Price, Nati Srebro, et al. 2016. Equality of opportunity in supervised learning. In Advances in neural
information processing systems. 3315–3323.

[56] Eszter Hargittai. 2007. Whose Space? Differences among Users and Non-Users of Social Network Sites. Journal
of Computer-Mediated Communication 13, 1 (10 2007), 276–297. https://doi.org/10.1111/j.1083-6101.2007.00396.x
arXiv:http://oup.prod.sis.lan/jcmc/article-pdf/13/1/276/22317170/jjcmcom0276.pdf

[57] Sarah Holland, Ahmed Hosny, Sarah Newman, Joshua Joseph, and Kasia Chmielinski. 2018. The dataset nutrition label:
A framework to drive higher data quality standards. arXiv preprint arXiv:1805.03677 (2018).

[58] Ayanna Howard and Jason Borenstein. 2018. The ugly truth about ourselves and our robot creations: the problem of bias
and social inequity. Science and engineering ethics 24, 5 (2018), 1521–1536.

[59] Lingxiao Huang and Nisheeth Vishnoi. 2019. Stable and Fair Classification. In International Conference on Machine
Learning. 2879–2890.

[60] Ben Hutchinson and Margaret Mitchell. 2019. 50 Years of Test (Un) fairness: Lessons for Machine Learning. In
Proceedings of the Conference on Fairness, Accountability, and Transparency. ACM, 49–58.

[61] L. Introna and H. Nissenbaum. 2000. Defining the Web: the politics of search engines. Computer 33, 1 (Jan 2000),
54–62. https://doi.org/10.1109/2.816269

[62] Ayush Jaiswal, Yue Wu, Wael AbdAlmageed, and Premkumar Natarajan. 2018. Unsupervised Adversarial Invariance.
(2018). arXiv:cs.LG/1809.10083

[63] Faisal Kamiran and Toon Calders. 2012. Data preprocessing techniques for classification without discrimination.
Knowledge and Information Systems 33, 1 (01 Oct 2012), 1–33. https://doi.org/10.1007/s10115-011-0463-8

[64] Faisal Kamiran and Indre ̇ Žliobaite ̇. 2013. Explainable and Non-explainable Discrimination in Classification. Springer
Berlin Heidelberg, Berlin, Heidelberg, 155–170. https://doi.org/10.1007/978-3-642-30487-3_8

[65] Toshihiro Kamishima, Shotaro Akaho, Hideki Asoh, and Jun Sakuma. 2012. Fairness-aware classifier with prejudice remover regularizer. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, 35–50.

[66] Michael Kearns, Seth Neel, Aaron Roth, and Zhiwei Steven Wu. 2018. Preventing Fairness Gerrymandering: Auditing and Learning for Subgroup Fairness. In International Conference on Machine Learning. 2569–2577.

[67] Michael Kearns, Seth Neel, Aaron Roth, and Zhiwei Steven Wu. 2019. An empirical study of rich subgroup fairness for machine learning. In Proceedings of the Conference on Fairness, Accountability, and Transparency. ACM, 100–109.

[68] Rogier Kievit, Willem Eduard Frankenhuis, Lourens Waldorp, and Denny Borsboom. 2013. Simpson’s paradox in psychological science: a practical guide. Frontiers in psychology 4 (2013), 513.

[69] Niki Kilbertus, Mateo Rojas Carulla, Giambattista Parascandolo, Moritz Hardt, Dominik Janzing, and Bernhard Schölkopf. 2017. Avoiding discrimination through causal reasoning. In Advances in Neural Information Processing Systems. 656–666.

[70] Jon Kleinberg, Sendhil Mullainathan, and Manish Raghavan. 2016. Inherent trade-offs in the fair determination of risk scores. arXiv preprint arXiv:1609.05807 (2016).

[71] Philipp Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. In MT summit, Vol. 5. 79–86.

[72] Emmanouil Krasanakis, Eleftherios Spyromitros-Xioufis, Symeon Papadopoulos, and Yiannis Kompatsiaris. 2018. Adaptive Sensitive Reweighting to Mitigate Bias in Fairness-aware Classification. In Proceedings of the 2018 World
Wide Web Conference (WWW ’18). International World Wide Web Conferences Steering Committee, Republic and
Canton of Geneva, Switzerland, 853–862. https://doi.org/10.1145/3178876.3186133

[73] Matt J Kusner, Joshua Loftus, Chris Russell, and Ricardo Silva. 2017. Counterfactual Fairness. In Advances in Neural
Information Processing Systems 30, I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and
R. Garnett (Eds.). Curran Associates, Inc., 4066–4076. http://papers.nips.cc/paper/6995-counterfactual-fairness.pdf

[74] Anja Lambrecht and Catherine E Tucker. 2018. Algorithmic bias? An empirical study into apparent gender-based discrimination in the display of STEM career ads. An Empirical Study into Apparent Gender-Based Discrimination in
the Display of STEM Career Ads (March 9, 2018) (2018).

[75] J Larson, S Mattu, L Kirchner, and J Angwin. 2016. Compas analysis. GitHub, available at: https://github.
com/propublica/compas-analysis[Google Scholar] (2016).

[76] Blake Lemoine, Brian Zhang, and M Mitchell. 2018. Mitigating Unwanted Biases with Adversarial Learning. (2018).

[77]KristinaLerman.2018.Computationalsocialscientistbeware:SimpsonâA ̆Z ́sparadoxinbehavioraldata.Journalof
Computational Social Science 1, 1 (2018), 49–58.

[78] Kristina Lerman and Tad Hogg. 2014. Leveraging position bias to improve peer recommendation. PloS one 9, 6 (2014),
e98914. [79]ZacharyCLipton,AlexandraChouldechova,andJulianMcAuley.2017.DoesmitigatingMLâA ̆Z ́sdisparateimpact
require disparate treatment? stat 1050 (2017), 19.

[80] Lydia T Liu, Sarah Dean, Esther Rolf, Max Simchowitz, and Moritz Hardt. 2018. Delayed Impact of Fair Machine
Learning. In Proceedings of the 35th International Conference on Machine Learning.

[81] Joshua R Loftus, Chris Russell, Matt J Kusner, and Ricardo Silva. 2018. Causal reasoning for algorithmic fairness.
arXiv preprint arXiv:1805.05859 (2018).

[82] Christos Louizos, Kevin Swersky, Yujia Li, Max Welling, and Richard Zemel. 2016. THE VARIATIONAL FAIR
AUTOENCODER. stat 1050 (2016), 4.

[83] Arjun K. Manrai, Birgit H. Funke, Heidi L. Rehm, Morten S. Olesen, Bradley A. Maron, Peter Szolovits, David M.
Margulies, Joseph Loscalzo, and Isaac S. Kohane. 2016. Genetic Misdiagnoses and the Potential for Health Dis- parities. New England Journal of Medicine 375, 7 (2016), 655–665. https://doi.org/10.1056/NEJMsa1507092 arXiv:https://doi.org/10.1056/NEJMsa1507092 PMID: 27532831.

[84] Chandler May, Alex Wang, Shikha Bordia, Samuel R Bowman, and Rachel Rudinger. 2019. On measuring social biases in sentence encoders. arXiv preprint arXiv:1903.10561 (2019).

[85] Ninareh Mehrabi, Fred Morstatter, Nanyun Peng, and Aram Galstyan. 2019. Debiasing Community Detection: The Importance of Lowly-Connected Nodes. arXiv preprint arXiv:1903.08136 (2019).

[86] Aditya Krishna Menon and Robert C Williamson. 2018. The cost of fairness in binary classification. In Proceedings of the 1st Conference on Fairness, Accountability and Transparency (Proceedings of Machine Learning Research), Sorelle A. Friedler and Christo Wilson (Eds.), Vol. 81. PMLR, New York, NY, USA, 107–118. http://proceedings.mlr. press/v81/menon18a.html

[87] Michele Merler, Nalini Ratha, Rogerio S Feris, and John R Smith. 2019. Diversity in Faces. arXiv preprint arXiv:1901.10436 (2019).

[88] Hannah Jean Miller, Jacob Thebault-Spieker, Shuo Chang, Isaac Johnson, Loren Terveen, and Brent Hecht. 2016. âA ̆IJBlissfullyHappyâA ̆ ̇IorâA ̆IJReadytoFightâA ̆ ̇I:VaryingInterpretationsofEmoji.InTenthInternationalAAAI Conference on Web and Social Media.

[89] I Minchev, G Matijevic, DW Hogg, G Guiglion, M Steinmetz, F Anders, C Chiappini, M Martig, A Queiroz, and C Scannapieco. 2019. Yule-Simpson’s paradox in Galactic Archaeology. arXiv preprint arXiv:1902.01421 (2019).

[90] Margaret Mitchell, Simone Wu, Andrew Zaldivar, Parker Barnes, Lucy Vasserman, Ben Hutchinson, Elena Spitzer,
Inioluwa Deborah Raji, and Timnit Gebru. 2019. Model Cards for Model Reporting. In Proceedings of the Conference on Fairness, Accountability, and Transparency (FAT* ’19). ACM, New York, NY, USA, 220–229. https://doi.org/10. 1145/3287560.3287596

[91] Fred Morstatter, Jürgen Pfeffer, Huan Liu, and Kathleen M Carley. 2013. Is the sample good enough? Comparing data from twitter’s streaming API with Twitter’s firehose. In 7th International AAAI Conference on Weblogs and Social Media, ICWSM 2013. AAAI press.

[92] Daniel Moyer, Shuyang Gao, Rob Brekelmans, Aram Galstyan, and Greg Ver Steeg. 2018. Invariant Representations without Adversarial Training. In Advances in Neural Information Processing Systems. 9084–9093.

[93] Amitabha Mukerjee, Rita Biswas, Kalyanmoy Deb, and Amrit P Mathur. 2002. Multi–objective evolutionary algorithms for the risk–return trade–off in bank loan management. International Transactions in operational research 9, 5 (2002), 583–597.

[94] Razieh Nabi, Daniel Malinsky, and Ilya Shpitser. 2018. Learning Optimal Fair Policies. arXiv preprint arXiv:1809.02244 (2018).

[95] Razieh Nabi and Ilya Shpitser. 2018. Fair inference on outcomes. In Thirty-Second AAAI Conference on Artificial Intelligence.

[96] Azadeh Nematzadeh, Giovanni Luca Ciampaglia, Filippo Menczer, and Alessandro Flammini. 2017. How algorithmic popularity bias hinders or promotes quality. arXiv preprint arXiv:1707.00574 (2017).

[97] Dong-Phuong Nguyen, Rilana Gravel, Rudolf Berend Trieschnigg, and Theo Meder. 2013. "How old do you think I am?": A study of language and age in Twitter. In Proceedings of the Seventh International AAAI Conference on Weblogs andSocialMedia,ICWSM2013.AAAIPress,439–448. eemcs-eprint-23604.

[98] Anne O’Keeffe and Michael McCarthy. 2010. The Routledge handbook of corpus linguistics. Routledge.

[99] Alexandra Olteanu, Carlos Castillo, Fernando Diaz, and Emre Kiciman. 2016. Social data: Biases, methodological
pitfalls, and ethical boundaries. (2016).

[100] Cathy O’Neil. 2016. Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy.
Crown Publishing Group, New York, NY, USA.

[101] Osonde A Osoba and William Welser IV. 2017. An intelligence in our image: The risks of bias and errors in artificial
intelligence. Rand Corporation.

[102] Edmund S Phelps. 1972. The statistical theory of racism and sexism. The american economic review 62, 4 (1972),
659–661.

[103] Geoff Pleiss, Manish Raghavan, Felix Wu, Jon Kleinberg, and Kilian Q Weinberger. 2017. On Fairness and Cali-
bration. In Advances in Neural Information Processing Systems 30, I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (Eds.). Curran Associates, Inc., 5680–5689. http://papers.nips.cc/paper/ 7151- on- fairness- and- calibration.pdf

[104] Marcelo OR Prates, Pedro H Avelar, and Luís C Lamb. 2018. Assessing gender bias in machine translation: a case study with Google Translate. Neural Computing and Applications (2018), 1–19.

[105] Bilal Qureshi, Faisal Kamiran, Asim Karim, and Salvatore Ruggieri. 2016. Causal discrimination discovery through propensity score analysis. arXiv preprint arXiv:1608.03735 (2016).

[106] Inioluwa Deborah Raji and Joy Buolamwini. 2019. Actionable auditing: Investigating the impact of publicly naming biased performance results of commercial ai products.

[107] M Redmond. 2011. Communities and crime unnormalized data set. UCI Machine Learning Repository. In website: http://www. ics. uci. edu/mlearn/MLRepository. html (2011).

[108] Lauren A Rivera. 2012. Hiring as cultural matching: The case of elite professional service firms. American sociological review 77, 6 (2012), 999–1022.

[109] Rachel Rudinger, Jason Naradowsky, Brian Leonard, and Benjamin Van Durme. 2018. Gender Bias in Coreference Resolution. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers). Association for Computational Linguistics, New Orleans, Louisiana, 8–14. https://doi.org/10.18653/v1/N18-2002

[110] Pedro Saleiro, Benedict Kuester, Abby Stevens, Ari Anisfeld, Loren Hinkson, Jesse London, and Rayid Ghani. 2018. Aequitas: A Bias and Fairness Audit Toolkit. arXiv preprint arXiv:1811.05577 (2018).

[111] Samira Samadi, Uthaipon Tantipongpipat, Jamie Morgenstern, Mohit Singh, and Santosh Vempala. 2018. The Price of Fair PCA: One Extra Dimension. In Proceedings of the 32Nd International Conference on Neural Information Processing Systems (NIPS’18). Curran Associates Inc., USA, 10999–11010. http://dl.acm.org/citation.cfm?id=3327546.3327755

[112] Nripsuta Ani Saxena. 2019. Perceptions of Fairness. In Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society (AIES ’19). ACM, New York, NY, USA, 537–538. https://doi.org/10.1145/3306618.3314314 Mehrabi et al.

[113] Nripsuta Ani Saxena, Karen Huang, Evan DeFilippis, Goran Radanovic, David C Parkes, and Yang Liu. 2019. How Do Fairness Definitions Fare?: Examining Public Attitudes Towards Algorithmic Definitions of Fairness. In Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society. ACM, 99–106.

[114] Tobias Schnabel, Adith Swaminathan, Ashudeep Singh, Navin Chandak, and Thorsten Joachims. 2016. Recom- mendations as Treatments: Debiasing Learning and Evaluation. In International Conference on Machine Learning. 1670–1679.

[115] Andrew D Selbst, Danah Boyd, Sorelle A Friedler, Suresh Venkatasubramanian, and Janet Vertesi. 2019. Fairness and abstraction in sociotechnical systems. In Proceedings of the Conference on Fairness, Accountability, and Transparency. ACM, 59–68.

[116] Shreya Shankar, Yoni Halpern, Eric Breck, James Atwood, Jimbo Wilson, and D Sculley. 2017. No Classification without Representation: Assessing Geodiversity Issues in Open Data Sets for the Developing World. stat 1050 (2017), 22.

[117] Richard Shaw and Manuel Corpas. [n. d.]. Further bias in personal genomics? ([n. d.]).

[118] Harini Suresh and John V Guttag. 2019. A Framework for Understanding Unintended Consequences of Machine
Learning. arXiv preprint arXiv:1901.10002 (2019).

[119] Songül Tolan, Marius Miron, Emilia Gómez, and Carlos Castillo. 2019. Why Machine Learning May Lead to
Unfairness: Evidence from Risk Assessment for Juvenile Justice in Catalonia. (2019).

[120] Zeynep Tufekci. 2014. Big questions for social media big data: Representativeness, validity and other methodological
pitfalls. In Eighth International AAAI Conference on Weblogs and Social Media.

[121] Berk Ustun, Yang Liu, and David Parkes. 2019. Fairness without Harm: Decoupled Classifiers with Preference
Guarantees. In Proceedings of the 36th International Conference on Machine Learning (Proceedings of Machine Learning Research), Kamalika Chaudhuri and Ruslan Salakhutdinov (Eds.), Vol. 97. PMLR, Long Beach, California, USA, 6373–6382. http://proceedings.mlr.press/v97/ustun19a.html

[122] Eva Vanmassenhove, Christian Hardmeier, and Andy Way. 2018. Getting gender right in neural machine translation. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. 3003–3008.

[123] Sahil Verma and Julia Rubin. 2018. Fairness definitions explained. In 2018 IEEE/ACM International Workshop on Software Fairness (FairWare). IEEE, 1–7.

[124] Selwyn Vickers, Mona Fouad, and Moon S Chen Jr. 2014. Enhancing Minority Participation in Clinical Trials (EMPaCT): laying the groundwork for improving minority clinical trial accrual. Cancer 120 (2014), vi–vii.

[125] Ting Wang and Dashun Wang. 2014. Why Amazon’s ratings might mislead you: The story of herding effects. Big data 2, 4 (2014), 196–204.

[126] Christo Wilson, Bryce Boe, Alessandra Sala, Krishna PN Puttaswamy, and Ben Y Zhao. 2009. User interactions in social networks and their implications. In Proceedings of the 4th ACM European conference on Computer systems. Acm, 205–218.

[127] Blake Woodworth, Suriya Gunasekar, Mesrob I Ohannessian, and Nathan Srebro. 2017. Learning non-discriminatory predictors. arXiv preprint arXiv:1702.06081 (2017).

[128] Yongkai Wu, Lu Zhang, and Xintao Wu. 2018. Fairness-aware Classification: Criterion, Convexity, and Bounds. (2018). arXiv:cs.LG/1809.04737

[129] Depeng Xu, Shuhan Yuan, Lu Zhang, and Xintao Wu. 2018. Fairgan: Fairness-aware generative adversarial networks. In 2018 IEEE International Conference on Big Data (Big Data). IEEE, 570–575.

[130] Irene Y Chen, Peter Szolovits, and Marzyeh Ghassemi. 2019. Can AI Help Reduce Disparities in General Medical and Mental Health Care? AMA journal of ethics 21 (02 2019), E167–179. https://doi.org/10.1001/amajethics.2019.167

[131] Muhammad Bilal Zafar, Isabel Valera, Manuel Gomez Rodriguez, and Krishna P Gummadi. 2015. Fairness constraints: Mechanisms for fair classification. arXiv preprint arXiv:1507.05259 (2015).

[132] Lu Zhang and Xintao Wu. 2017. Anti-discrimination learning: a causal modeling-based framework. International Journal of Data Science and Analytics 4, 1 (01 Aug 2017), 1–16. https://doi.org/10.1007/s41060-017-0058-x

[133] Lu Zhang, Yongkai Wu, and Xintao Wu. 2016. On Discrimination Discovery Using Causal Networks. In Social, Cultural, and Behavioral Modeling, Kevin S. Xu, David Reitter, Dongwon Lee, and Nathaniel Osgood (Eds.). Springer International Publishing, Cham, 83–93.

[134] Lu Zhang, Yongkai Wu, and Xintao Wu. 2016. Situation Testing-based Discrimination Discovery: A Causal Inference Approach. In Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence (IJCAI’16). AAAI Press, 2718–2724. http://dl.acm.org/citation.cfm?id=3060832.3061001

[135] Lu Zhang, Yongkai Wu, and Xintao Wu. 2017. Achieving non-discrimination in data release. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 1335–1344.

[136] Lu Zhang, Yongkai Wu, and Xintao Wu. 2017. A Causal Framework for Discovering and Removing Direct and Indirect Discrimination. In Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, IJCAI-17. 3929–3935. https://doi.org/10.24963/ijcai.2017/549

[137] L. Zhang, Y. Wu, and X. Wu. 2018. Causal Modeling-Based Discrimination Discovery and Removal: Criteria, Bounds, and Algorithms. IEEE Transactions on Knowledge and Data Engineering (2018), 1–1. https://doi.org/10.1109/TKDE. 2018.2872988

[138] Jieyu Zhao, Tianlu Wang, Mark Yatskar, Ryan Cotterell, Vicente Ordonez, and Kai-Wei Chang. 2019. Gender Bias in Contextualized Word Embeddings. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). 629–634.

[139] Jieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, and Kai-Wei Chang. 2017. Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing.

[140] Jieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, and Kai-Wei Chang. 2018. Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods. (2018). arXiv:cs.CL/1804.06876

[141] Jieyu Zhao, Yichao Zhou, Zeyu Li, Wei Wang, and Kai-Wei Chang. 2018. Learning Gender-Neutral Word Embeddings. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. 4847–4853.

[142] James Zou and Londa Schiebinger. 2018. AI can be sexist and racist it’s time to make it fair. (2018).

# 2 Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour

GPU

Batch Normalization (BN)
NVIDIA Collective Communication Library (NCCL)3
stochastic gradient descent(SGD)


References

[1] J. Bagga, H. Morsy, and Z. Yao. Opening
designs for 6-pack and Wedge 100. https://code.facebook.com/posts/203733993317833/opening-designs-for-6-pack-and-wedge-100, 2016.

[2] M. Barnett, L. Shuler, R. van De Geijn, S. Gupta, D. G.
Payne, and J. Watts. Interprocessor collective communication
library (intercom). In Scalable High-Performance Computing
Conference, 1994.

[3] L. Bottou. Curiously fast convergence of some stochastic
gradient descent algorithms. Unpublished open problem offered
to the attendance of the SLDS 2009 conference, 2009.

[4] L. Bottou, F. E. Curtis, and J. Nocedal. Opt. methods for
large-scale machine learning. arXiv:1606.04838, 2016.

[5] J. Chen, X. Pan, R. Monga, S. Bengio, and R. Jozefowicz.
Revisiting Distributed Synchronous SGD.
arXiv:1604.00981, 2016.

[6] K. Chen and Q. Huo. Scalable training of deep learning machines
by incremental block training with intra-block parallel
optimization and blockwise model-update filtering. In
ICASSP, 2016.

[7] R. Collobert, J. Weston, L. Bottou, M. Karlen,
K. Kavukcuoglu, and P. Kuksa. Natural language processing
(almost) from scratch. JMLR, 2011.

[8] J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang,
E. Tzeng, and T. Darrell. Decaf: A deep convolutional activation
feature for generic visual recognition. In ICML, 2014.

[9] R. Girshick. Fast R-CNN. In ICCV, 2015.

[10] R. Girshick, J. Donahue, T. Darrell, and J. Malik. Rich feature
hierarchies for accurate object detection and semantic
segmentation. In CVPR, 2014.

[11] W. Gropp, E. Lusk, and A. Skjellum. Using MPI: Portable
Parallel Programming with the Message-Passing Interface.
MIT Press, Cambridge, MA, 1999.

[12] S. Gross and M. Wilber. Training and investigating Residual
Nets. https://github.com/facebook/fb.resnet.torch, 2016.

[13] M. G¨urb¨uzbalaban, A. Ozdaglar, and P. Parrilo. Why
random reshuffling beats stochastic gradient descent.
arXiv:1510.08560, 2015.

[14] K. He, G. Gkioxari, P. Doll´ar, and R. Girshick. Mask RCNN.
arXiv:1703.06870, 2017.

[15] K. He, X. Zhang, S. Ren, and J. Sun. Delving deep into
rectifiers: Surpassing human-level performance on imagenet
classification. In ICCV, 2015.

[16] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning
for image recognition. In CVPR, 2016.

[17] G. Hinton, L. Deng, D. Yu, G. E. Dahl, A.-r. Mohamed,
N. Jaitly, A. Senior, V. Vanhoucke, P. Nguyen, T. N. Sainath,
et al. Deep neural networks for acoustic modeling in speech
recognition: The shared views of four research groups. IEEE
Signal Processing Magazine, 2012.

[18] I. Hubara, M. Courbariaux, D. Soudry, R. El-Yaniv, and
Y. Bengio. Quantized neural networks: Training neural
networks with low precision weights and activations.
arXiv:1510.08560, 2016.

[19] S. Ioffe and C. Szegedy. Batch normalization: Accelerating
deep network training by reducing internal covariate shift. In
ICML, 2015.

[20] N. S. Keskar, D. Mudigere, J. Nocedal, M. Smelyanskiy, and
P. T. P. Tang. On large-batch training for deep learning: Generalization
gap and sharp minima. ICLR, 2017.

[21] A. Krizhevsky. One weird trick for parallelizing convolutional
neural networks. arXiv:1404.5997, 2014.

[22] A. Krizhevsky, I. Sutskever, and G. Hinton. ImageNet classification
with deep convolutional neural nets. In NIPS, 2012.

[23] Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E.
Howard, W. Hubbard, and L. D. Jackel. Backpropagation
applied to handwritten zip code recognition. Neural computation,
1989.

[24] K. Lee. Introducing Big Basin: Our next-generation
AI hardware. https://code.facebook.com/posts/
1835166200089399/introducing-big-basin, 2017.

[25] M. Li. Scaling Distributed Machine Learning with System
and Algorithm Co-design. PhD thesis, Carnegie Mellon University,
2017.

[26] T.-Y. Lin, P. Doll´ar, R. Girshick, K. He, B. Hariharan, and
S. Belongie. Feature pyramid networks for object detection.
In CVPR, 2017.

[27] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan,
P. Doll´ar, and C. L. Zitnick. Microsoft COCO: Common
objects in context. In ECCV. 2014.

[28] J. Long, E. Shelhamer, and T. Darrell. Fully convolutional
networks for semantic segmentation. In CVPR, 2015.

[29] Y. Nesterov. Introductory lectures on convex optimization: A
basic course. Springer, 2004.

[30] R. Rabenseifner. Optimization of collective reduction operations.
In ICCS. Springer, 2004.

[31] S. Ren, K. He, R. Girshick, and J. Sun. Faster R-CNN: Towards
real-time object detection with region proposal networks.
In NIPS, 2015.

[32] H. Robbins and S. Monro. A stochastic approximation
method. The annals of mathematical statistics, 1951.

[33] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh,
S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein,
A. C. Berg, and L. Fei-Fei. ImageNet Large Scale Visual
Recognition Challenge. IJCV, 2015.

[34] P. Sermanet, D. Eigen, X. Zhang, M. Mathieu, R. Fergus,
and Y. LeCun. Overfeat: Integrated recognition, localization
and detection using convolutional networks. In ICLR, 2014.

[35] K. Simonyan and A. Zisserman. Very deep convolutional
networks for large-scale image recognition. In ICLR, 2015.

[36] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed,
D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich.
Going deeper with convolutions. In CVPR, 2015.

[37] R. Thakur, R. Rabenseifner, and W. Gropp. Optimization of
collective comm. operations in MPICH. IJHPCA, 2005.

[38] Y. Wu, M. Schuster, Z. Chen, Q. V. Le, M. Norouzi,
W. Macherey, M. Krikun, Y. Cao, Q. Gao, K. Macherey,
et al. Google’s neural machine translation system: Bridging
the gap between human and machine translation.
arXiv:1609.08144, 2016.

[39] S. Xie, R. Girshick, P. Doll´ar, Z. Tu, and K. He. Aggregated
residual transformations for deep neural networks. In CVPR,
2017.

[40] W. Xiong, J. Droppo, X. Huang, F. Seide, M. Seltzer, A. Stolcke,
D. Yu, and G. Zweig. The Microsoft 2016 Conversational
Speech Recognition System. arXiv:1609.03528, 2016.

[41] M. D. Zeiler and R. Fergus. Visualizing and understanding
convolutional neural networks. In ECCV, 2014.

# 3 Bayesian Uncertainty Estimation for Batch Normalized Deep Networks

Constant Uncertainty Dropout (CUDO).
Continuous Ranked Probability Score (CRPS)
cross-validation (CV)
Monte Carlo Dropout (MCDO)
Monte Carlo Batch Normalization (MCBN)
Multiplicative Normalizing Flows for variational Bayesian networks (MNF)
Log likelihood (PLL)
variational inference (VI)
Probabilistic backpropagation (PBP)
Kullback-Leibler (KL)

References

Bui, T. D., Hern´andez-Lobato, D., Li, Y., Hern´andez-
Lobato, J. M., and Turner, R. E. Deep Gaussian Processes
for Regression using Approximate Expectation
Propagation. In ICML, 2016.

Chen, X., Kundu, K., Zhang, Z., Ma, H., Fidler, S., and Urtasun,
R. Monocular 3d object detection for autonomous
driving. In Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition, pp. 2147–2156,
2016.

Djuric, U., Zadeh, G., Aldape, K., and Diamandis, P. Precision
histology: how deep learning is poised to revitalize
histomorphology for personalized cancer care. npj Precision
Oncology, 1(1):22, 2017.

Esteva, A., Kuprel, B., Novoa, R. A., Ko, J., Swetter, S. M.,
Blau, H. M., and Thrun, S. Dermatologist-level classification
of skin cancer with deep neural networks. Nature,
Feb 2017.

Gal, Y. Uncertainty in Deep Learning. PhD thesis, University
of Cambridge, 2016.

Gal, Y. and Ghahramani, Z. Dropout as a Bayesian Approximation
: Representing Model Uncertainty in Deep
Learning. ICML, 48:1–10, 2015.

Ghahramani, Z. Delve Datasets. University of Toronto,
1996. URL http://www.cs.toronto.edu/
{˜}delve/data/kin/desc.html.

Ghahramani, Z. Probabilistic machine learning and artificial
intelligence. Nature, 521(7553):452–459, May
2015.

Gneiting, T. and Raftery, A. E. Strictly Proper Scoring
Rules, Prediction, and Estimation. Journal of the American
Statistical Association, 102(477):359–378, 2007.

Goodfellow, I. J., Shlens, J., and Szegedy, C. Explaining
and harnessing adversarial examples. arXiv preprint
arXiv:1412.6572, 2014.

Graves, A. Practical Variational Inference for Neural Networks.
NIPS, 2011.

Hern´andez-Lobato, J. M. and Adams, R. Probabilistic
backpropagation for scalable learning of bayesian neural
networks. In International Conference on Machine
Learning, pp. 1861–1869, 2015.

Hinton, G. E. and Van Camp, D. Keeping the neural networks
simple by minimizing the description length of
the weights. In Proceedings of the sixth annual conference
on Computational learning theory, pp. 5–13. ACM,
1993.

Ioffe, S. Batch renormalization: Towards reducing minibatch
dependence in batch-normalized models. CoRR,
abs/1702.03275, 2017. URL http://arxiv.org/
abs/1702.03275.

Ioffe, S. and Szegedy, C. Batch Normalization: Accelerating
Deep Network Training by Reducing Internal Covariate
Shift. Arxiv, 2015. URL http://arxiv.
org/abs/1502.03167.

Karpathy, A. Convnetjs demo: toy 1d regression, 2015.
URL http://cs.stanford.edu/people/karpathy/convnetjs/demo/regression.html.

Kendall, A., Badrinarayanan, V., and Cipolla, R. Bayesian
SegNet: Model Uncertainty in Deep Convolutional
Encoder-Decoder Architectures for Scene Understanding.
CoRR, abs/1511.0, 2015. URL http://arxiv.org/abs/1511.02680.

Kingma, D. P. and Welling, M. Auto-Encoding Variational
Bayes. In ICLR, 2014.

Krizhevsky, A. and Hinton, G. Learning multiple layers of
features from tiny images. 2009.

Krueger, D., Huang, C.-W., Islam, R., Turner, R., Lacoste,
A., and Courville, A. Bayesian hypernetworks. arXiv
preprint arXiv:1710.04759, 2017.

Lehmann, E. L. Elements of Large-Sample Theory.
Springer Verlag, New York, 1999. ISBN 0387985956.
Li, Y. and Gal, Y. Dropout Inference in Bayesian Neural
Networks with Alpha-divergences. arXiv, 2017.

Louizos, C. and Welling, M. Multiplicative normalizing
flows for variational Bayesian neural networks.
In Precup, D. and Teh, Y. W. (eds.), Proceedings of
the 34th International Conference on Machine Learning,
volume 70 of Proceedings of Machine Learning
Research, pp. 2218–2227, International Convention
Centre, Sydney, Australia, 06–11 Aug 2017. PMLR.
URL http://proceedings.mlr.press/v70/louizos17a.html.

MacKay, D. J. A practical bayesian framework for backpropagation
networks. Neural computation, 4(3):448–
472, 1992.

Neal, R. M. Bayesian Learning for Neural Networks. PhD
thesis, University of Toronto, 1995.

Neal, R. M. Bayesian learning for neural networks, volume
118. Springer Science & Business Media, 2012.

Selten, R. Axiomatic characterization of the quadratic scoring
rule. Experimental Economics, 1(1):43–62, 1998.
Bayesian Uncertainty Estimation for Batch Normalized Deep Networks

Shen, L. End-to-end training for whole image breast cancer
diagnosis using an all convolutional design. arXiv
preprint arXiv:1708.09427, 2017.
University of California, I. UC Irvine Machine Learning
Repository, 2017. URL https://archive.ics.uci.edu/ml/index.html.

Wang, S. I. and Manning, C. D. Fast dropout training.
Proceedings of the 30th International Conference
on Machine Learning, 28:118–126, 2013.
URL http://machinelearning.wustl.edu/mlpapers/papers/wang13a.

# 4 Certifying and removing disparate impact
NGO
BER

Disparate Impact(DI)

US Equal Employment Opportunity Commission (EEOC)

Logistic Regression(LR)

Regularized Logistic Regression(RLR)


References
[1] S. Barocas and A. D. Selbst. Big data’s disparate impact. Technical report, available at
SSRN: http://ssrn.com/abstract=2477899, 2014.

[2] T. Calders, F. Kamiran, and M. Pechenizkiy. Building classifiers with independency
constraints. In ICDM Workshop Domain Driven Data Mining, pages 13–18, 2009.

[3] T. Calders and S. Verwer. Three naive bayes approaches for discrimination-free
classification. Data Mining journal; special issue with selected papers from ECML/PKDD,
2010.

[4] C. Dwork, M. Hardt, T. Pitassi, O. Reingold, and R. Zemel. Fairness through awareness.
In Proc. of Innovations in Theoretical Computer Science, 2012.

[5] R.-E. Fan, K.-W. Chang, C.-J. Hsieh, X.-R. Wang, and C.-J. Lin. Liblinear: A library for
large linear classification. J. of Machine Learning Research, 9:1871–1874, 2008.

[6] H. Hodson. No one in control: The algorithms that run our lives. New Scientist, Feb.
04, 2015.

[7] T. Joachims. A support vector method for multivariate performance measures. In
Proc. of Intl. Conf. on Machine Learning, pages 377–384. ACM, 2005.
8 Acknowledgments 25

[8] F. Kamiran and T. Calders. Classifying without discriminating. In Proc. of the IEEE
International Conference on Computer, Control and Communication, 2009.

[9] T. Kamishima, S. Akaho, H. Asoh, and J. Sakuma. Fairness-aware classifier with
prejudice remover regularizer. Machine Learning and Knowledge Discovery in Databases,
pages 35–50, 2012.

[10] T. Kamishima, S. Akaho, and J. Sakuma. Fairness aware learning through regularization
approach. In Proc of. Intl. Conf. on Data Mining, pages 643–650, 2011.

[11] B. T. Luong, S. Ruggieri, and F. Turini. k-nn as an implementation of situation testing
for discrimination discovery and prevention. In Proc. of Intl. Conf. on Knowledge
Discovery and Data Mining, KDD ’11, pages 502–510, 2011.

[12] A. Menon, H. Narasimhan, S. Agarwal, and S. Chawla. On the statistical consistency
of algorithms for binary classification under class imbalance. In Proc. 30th. ICM, pages
603–611, 2013.

[13] W. Miao. Did the results of promotion exams have a disparate impact on minorities?
Using statistical evidence in Ricci v. DeStefano. J. of Stat. Ed., 19(1), 2011.

[14] J. Pearl. Understanding simpson’s paradox. The American Statistician, 2014.

[15] D. Pedreschi, S. Ruggieri, and F. Turini. Integrating induction and deduction for
finding evidence of discrimination. In Proc. of Intl. Conf. on Artificial Intelligence and
Law, ICAIL ’09, pages 157–166, 2009.

[16] D. Pedreschi, S. Ruggieri, and F. Turini. A study of top-k measures for discrimination
discovery. In Proc. of Symposium on Applied Computing, SAC ’12, pages 126–131, 2012.

[17] J. L. Peresie. Toward a coherent test for disparate impact discrimination. Indiana Law
Journal, 84(3):Article 1, 2009.

[18] J. Podesta, P. Pritzker, E. J. Moniz, J. Holdren, and J. Zients. Big data: seizing opportunities,
preserving values. Executive Office of the President, May 2014.

[19] A. Romei and S. Ruggieri. A multidisciplinary survey on discrimination analysis. The
Knowledge Engineering Review, pages 1–57, April 3 2013.

[20] Supreme Court of the United States. Griggs v. Duke Power Co. 401 U.S. 424, March 8,
1971.

[21] Supreme Court of the United States. Watson v. Fort Worth Bank & Trust. 487 U.S. 977,
995, 1988.

[22] Supreme Court of the United States. Ricci v. DeStefano. 557 U.S. 557, 174, 2009.
A A Survey of Discrimination Types 26

[23] Texas House of Representatives. House bill 588. 75th Legislature, 1997.

[24] The Leadership Conference. Civil rights principles for the era of big data.
http://www.civilrights.org/press/2014/civil-rights-principles-big-data.html, Feb.
27, 2014.

[25] The U.S. EEOC. Uniform guidelines on employee selection procedures, March 2, 1979.

[26] R. Zemel, Y. Wu, K. Swersky, T. Pitassi, and C. Dwork. Learning fair representations.
In Proc. of Intl. Conf. on Machine Learning, pages 325–333, 2013.

[27] M.-J. Zhao, N. Edakunni, A. Pocock, and G. Brown. Beyond Fano’s inequality: bounds
on the optimal F-score, BER, and cost-sensitive risk and their implications. J. of Machine
Learning Research, 14(1):1033–1090, 2013.

# 5 Class-Balanced Loss Based on Effective Number of Samles

ResNets

Class-Balanced(CB) Loss
Convolutional Neural Networks(CNNs)
Softmax (SM)
Sigmoid(SGM)

References
[1] The iNaturalist 2018 Competition Dataset. https://
github.com/visipedia/inat_comp. 5, 6
[2] M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean,
M. Devin, S. Ghemawat, G. Irving, M. Isard, et al. Tensorflow:
A system for large-scale machine learning. In OSDI,
2016. 6
[3] S. Bengio. Sharing representations for long tail computer
vision problems. In ICMI, 2015. 1, 2
[4] M. Buda, A. Maki, and M. A. Mazurowski. A systematic
study of the class imbalance problem in convolutional neural
networks. Neural Networks, 2018. 1, 2
[5] N. V. Chawla, K. W. Bowyer, L. O. Hall, and W. P.
Kegelmeyer. Smote: synthetic minority over-sampling technique.
JAIR, 2002. 2
[6] Y. Cui, Y. Song, C. Sun, A. Howard, and S. Belongie. Large
scale fine-grained categorization and domain-specific transfer
learning. In CVPR, 2018. 2
[7] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-
Fei. Imagenet: A large-scale hierarchical image database. In
CVPR, 2009. 1
[8] Q. Dong, S. Gong, and X. Zhu. Class rectification hard mining
for imbalanced deep learning. In ICCV, 2017. 2
[9] C. Drummond, R. C. Holte, et al. C4. 5, class imbalance, and
cost sensitivity: why under-sampling beats over-sampling. In
ICML Workshop, 2003. 2
[10] C. Elkan. The foundations of cost-sensitive learning. In IJCAI,
2001. 2
[11] Y. Freund and R. E. Schapire. A decision-theoretic generalization
of on-line learning and an application to boosting.
Journal of computer and system sciences, 1997. 2
[12] Y. Geifman and R. El-Yaniv. Deep active learning over the
long tail. arXiv preprint arXiv:1711.00941, 2017. 1, 2
[13] P. Goyal, P. Doll´ar, R. Girshick, P. Noordhuis,
L. Wesolowski, A. Kyrola, A. Tulloch, Y. Jia, and K. He.
Accurate, large minibatch sgd: training imagenet in 1 hour.
arXiv preprint arXiv:1706.02677, 2017. 6
[14] H. He, Y. Bai, E. A. Garcia, and S. Li. Adasyn: Adaptive
synthetic sampling approach for imbalanced learning. In
IEEE International Joint Conference on Neural Networks,
2008. 2
[15] H. He and E. A. Garcia. Learning from imbalanced data.
IEEE Transactions on Knowledge & Data Engineering,
2008. 1
[16] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning
for image recognition. In CVPR, 2016. 1, 5, 9
[17] C. Huang, Y. Li, C. Change Loy, and X. Tang. Learning deep
representation for imbalanced classification. In CVPR, 2016.
1, 2
[18] S. Janson. Random coverings in several dimensions. Acta
Mathematica, 1986. 2, 3
[19] N. Japkowicz and S. Stephen. The class imbalance problem:
A systematic study. Intelligent data analysis, 2002. 1
[20] H. Kahn and A. W. Marshall. Methods of reducing sample
size in monte carlo computations. Journal of the Operations
Research Society of America, 1953. 2
[21] M. G. Kendall et al. The advanced theory of statistics. The
advanced theory of statistics., (2nd Ed), 1946. 1
[22] S. H. Khan, M. Hayat, M. Bennamoun, F. A. Sohel, and
R. Togneri. Cost-sensitive learning of deep feature representations
from imbalanced data. IEEE transactions on neural
networks and learning systems, 2018. 2
[23] P.W. Koh and P. Liang. Understanding black-box predictions
via influence functions. In ICML, 2017. 2
[24] A. Krizhevsky and G. Hinton. Learning multiple layers of
features from tiny images. Technical report, Citeseer, 2009.
1, 5, 9
[25] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet
classification with deep convolutional neural networks. In
Neural Information Processing Systems, 2012. 1
[26] T.-Y. Lin, P. Goyal, R. Girshick, K. He, and P. Doll´ar. Focal
loss for dense object detection. PAMI, 2018. 2, 5, 6
[27] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan,
P. Doll´ar, and C. L. Zitnick. Microsoft coco: Common
objects in context. In ECCV, 2014. 1
[28] D. Mahajan, R. Girshick, V. Ramanathan, K. He, M. Paluri,
Y. Li, A. Bharambe, and L. van der Maaten. Exploring the
limits of weakly supervised pretraining. In ECCV, 2018. 2
[29] T. Malisiewicz, A. Gupta, and A. A. Efros. Ensemble of
exemplar-svms for object detection and beyond. In ICCV,
2011. 2
[30] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and
J. Dean. Distributed representations of words and phrases
and their compositionality. In Neural Information Processing
Systems, 2013. 2
[31] W. Ouyang, X. Wang, C. Zhang, and X. Yang. Factors in
finetuning deep model for object detection with long-tail distribution.
In CVPR, 2016. 1, 2
[32] M. Ren, W. Zeng, B. Yang, and R. Urtasun. Learning to
reweight examples for robust deep learning. In ICML, 2018.
2
[33] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh,
S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein,
et al. Imagenet large scale visual recognition challenge.
IJCV, 2015. 1, 5, 6
[34] N. Sarafianos, X. Xu, and I. A. Kakadiaris. Deep imbalanced
attribute classification using visual attention aggregation. In
ECCV, 2018. 2
[35] L. Shen, Z. Lin, and Q. Huang. Relay backpropagation for
effective learning of deep convolutional neural networks. In
ECCV, 2016. 2
[36] K. Simonyan and A. Zisserman. Very deep convolutional
networks for large-scale image recognition. arXiv preprint
arXiv:1409.1556, 2014. 1
[37] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed,
D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich.
Going deeper with convolutions. In CVPR, 2015. 1
[38] K. M. Ting. A comparative study of cost-sensitive boosting
algorithms. In ICML, 2000. 2
[39] A. Torralba, R. Fergus, and W. T. Freeman. 80 million tiny
images: A large data set for nonparametric object and scene
recognition. PAMI, 2008. 1
[40] G. Van Horn, O. Mac Aodha, Y. Song, Y. Cui, C. Sun,
A. Shepard, H. Adam, P. Perona, and S. Belongie. The inaturalist
species classification and detection dataset. In CVPR,
2018. 1, 5, 6
[41] G. Van Horn and P. Perona. The devil is in the tails:
Fine-grained classification in the wild. arXiv preprint
arXiv:1709.01450, 2017. 1
[42] C. Wah, S. Branson, P. Welinder, P. Perona, and S. Belongie.
The caltech-ucsd birds-200-2011 dataset. California Institute
of Technology, 2011. 1
[43] Y.-X.Wang, D. Ramanan, and M. Hebert. Learning to model
the tail. In Neural Information Processing Systems, 2017. 1,
2
[44] X. Yin, X. Yu, K. Sohn, X. Liu, and M. Chandraker. Feature
transfer learning for deep face recognition with long-tail
data. arXiv preprint arXiv:1803.09014, 2018. 1, 2
[45] C. You, C. Li, D. P. Robinson, and R. Vidal. A scalable
exemplar-based subspace clustering algorithm for classimbalanced
data. In European Conference on Computer Vision,
2018. 2
[46] S. Zagoruyko and N. Komodakis. Wide residual networks.
In BMVC, 2016. 6
[47] X. Zhang, Z. Fang, Y. Wen, Z. Li, and Y. Qiao. Range loss
for deep face recognition with long-tailed training data. In
CVPR, 2017. 1, 2
[48] B. Zhou, A. Lapedriza, A. Khosla, A. Oliva, and A. Torralba.
Places: A 10 million image database for scene recognition.
PAMI, 2017. 1
[49] Z.-H. Zhou and X.-Y. Liu. Training cost-sensitive neural
networks with methods addressing the class imbalance problem.
IEEE Transactions on Knowledge and Data Engineering,
2006. 2
[50] Y. Zou, Z. Yu, B. V. Kumar, and J. Wang. Unsupervised
domain adaptation for semantic segmentation via classbalanced
self-training. In ECCV, 2018. 2

# 6 Classification with Fairness Constraints: A Meta-Algorithm with Probable Guarantees

US
NYPD
optimization(OPT)

References
[1] ACM. Statement on algorithmic transparency and accountability. https://
www.acm.org/binaries/content/assets/public-policy/2017_usacm_statement_
algorithms.pdf, 2017.
[2] An Act. Civil rights act of 1964. Title VII, Equal Employment Opportunities, 1964.
[3] Alekh Agarwal, Alina Beygelzimer, Miroslav Dudík, John Langford, and Hanna M.
Wallach. A reductions approach to fair classification. In Proceedings of the 35th International
Conference on Machine Learning, ICML 2018, Stockholmsmässan, Stockholm,
Sweden, July 10-15, 2018, pages 60–69, 2018.
[4] Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner. https://github.com/
propublica/compas-analysis, 2016.
[5] Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner. Machine bias: There’s
software used across the country to predict future criminals. and it’s biased against
blacks. ProPublica, May, 2016.
[6] Solon Barocas and Andrew D Selbst. Big data’s disparate impact. California Law
Review, 2016.
[7] Richard Berk. The role of race in forecasts of violent crime. Race and social problems,
2009.
[8] Stephen Boyd and Almir Mutapcic. Stochastic subgradient methods. Lecture Notes for
EE364b, Stanford University, 2008.
[9] Toon Calders and Sicco Verwer. Three naive bayes approaches for discrimination-free
classification. Data Min. Knowl. Discov., 21(2):277–292, 2010.
[10] L. Elisa Celis, Amit Deshpande, Tarun Kathuria, Damian Straszak, and Nisheeth K.
Vishnoi. On the complexity of constrained determinantal point processes. In Approximation,
Randomization, and Combinatorial Optimization. Algorithms and Techniques,
APPROX/RANDOM 2017, August 16-18, 2017, Berkeley, CA, USA, pages 36:1–36:22,
2017.
[11] L. Elisa Celis, Amit Deshpande, Tarun Kathuria, and Nisheeth K Vishnoi. How to be
fair and diverse? In Fairness, Accountability, and Transparency in Machine Learning,
2016.
[12] L Elisa Celis, Lingxiao Huang, and Nisheeth K Vishnoi. Multiwinner voting with fairness
constraints. In Proceedings of the Twenty-seventh International Joint Conference on
Artificial Intelligence and the Twenty-third European Conference on Artificial Intelligence,
IJCAI-ECAI, 2018.

[13] L. Elisa Celis, Vijay Keswani, Amit Deshpande, Tarun Kathuria, Damian Straszak, and
Nisheeth K. Vishnoi. Fair and diverse DPP-based data summarization. In ICML, 2018.
[14] L. Elisa Celis, Damian Straszak, and Nisheeth K. Vishnoi. Ranking with fairness
constraints. In Proceedings of the fourty-fifth International Colloquium on Automata,
Languages, and Programming ICALP, 2018.
[15] L. Elisa Celis and Nisheeth K Vishnoi. Fair personalization. In Fairness, Accountability,
and Transparency in Machine Learning, 2017.
[16] Alexandra Chouldechova. Fair prediction with disparate impact: A study of bias in
recidivism prediction instruments. CoRR, abs/1703.00056, 2017.
[17] Sam Corbett-Davies, Emma Pierson, Avi Feller, Sharad Goel, and Aziz Huq. Algorithmic
decision making and the cost of fairness. In Proceedings of the 23rd ACM
SIGKDD International Conference on Knowledge Discovery and Data Mining, Halifax,
NS, Canada, August 13 - 17, 2017, pages 797–806, 2017.
[18] Amit Datta, Michael Carl Tschantz, and Anupam Datta. Automated experiments on
ad privacy settings. Proceedings on Privacy Enhancing Technologies, 2015.
[19] Bill Dedman et al. The color of money. Atlanta Journal-Constitution, 1988.
[20] Dua Dheeru and Efi Karra Taniskidou. UCI machine learning repository. http://
archive.ics.uci.edu/ml, 2017.
[21] William Dieterich, Christina Mendoza, and Tim Brennan. Compas risk scales: Demonstrating
accuracy equity and predictive parity. Northpoint Inc, 2016.
[22] Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel.
Fairness through awareness. In Innovations in Theoretical Computer Science 2012,
Cambridge, MA, USA, January 8-10, 2012, pages 214–226. ACM, 2012.
[23] Cynthia Dwork, Nicole Immorlica, Adam Tauman Kalai, and Mark D. M. Leiserson.
Decoupled classifiers for group-fair and efficient machine learning. In Fairness, Accountability,
and Transparency in Machine Learning, pages 119–133, 2018.
[24] ENTHOUGHT. SciPy. https://www.scipy.org/, 2018.
[25] Michael Feldman, Sorelle A Friedler, John Moeller, Carlos Scheidegger, and Suresh
Venkatasubramanian. Certifying and removing disparate impact. In Proceedings of
the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data
Mining, Sydney, NSW, Australia, August 10-13, 2015, pages 259–268. ACM, 2015.
[26] Benjamin Fish, Jeremy Kun, and Ádám D Lelkes. A confidence-based approach
for balancing fairness and accuracy. In Proceedings of the 2016 SIAM International
Conference on Data Mining, Miami, Florida, USA, May 5-7, 2016, pages 144–152.
SIAM, 2016.

[27] Anthony W Flores, Kristin Bechtel, and Christopher T Lowenkamp. False positives, false
negatives, and false analyses: A rejoinder to machine bias: There’s software used across
the country to predict future criminals. and it’s biased against blacks. Fed. Probation,
80:38, 2016.
[28] Sorelle A Friedler, Carlos Scheidegger, and Suresh Venkatasubramanian. On the (im)
possibility of fairness. arXiv preprint arXiv:1609.07236, 2016.
[29] Naman Goel, Mohammad Yaghini, and Boi Faltings. Non-discriminatory machine
learning through convex fairness criteria. In Proceedings of the Thirty-Second AAAI
Conference on Artificial Intelligence, New Orleans, Louisiana, USA, February 2-7, 2018,
2018.
[30] Sharad Goel, Justin M Rao, Ravi Shroff, et al. Precinct or prejudice? understanding
racial disparities in new york city’s stop-and-frisk policy. The Annals of Applied Statistics,
10(1):365–394, 2016.
[31] Gabriel Goh, Andrew Cotter, Maya R. Gupta, and Michael P. Friedlander. Satisfying
real-world goals with dataset constraints. In Advances in Neural Information Processing
Systems 29: Annual Conference on Neural Information Processing Systems 2016,
December 5-10, 2016, Barcelona, Spain, pages 2415–2423, 2016.
[32] Nina Grgic-Hlaca, Elissa M Redmiles, Krishna P Gummadi, and Adrian Weller. Human
perceptions of fairness in algorithmic decision making: A case study of criminal risk
prediction. In Proceedings of the 2018 World Wide Web Conference on World Wide
Web, WWW 2018, Lyon, France, April 23-27, 2018, pages 903–912, 2018.
[33] Nina Grgic-Hlaca, Muhammad Bilal Zafar, Krishna P Gummadi, and Adrian Weller.
Beyond distributive fairness in algorithmic decision making: Feature selection for
procedurally fair learning. In Proceedings of the Thirty-Second AAAI Conference on
Artificial Intelligence, New Orleans, Louisiana, USA, February 2-7, 2018, 2018.
[34] Moritz Hardt, Eric Price, and Nati Srebro. Equality of opportunity in supervised
learning. In Advances in Neural Information Processing Systems 29: Annual Conference
on Neural Information Processing Systems 2016, December 5-10, 2016, Barcelona, Spain,
pages 3315–3323, 2016.
[35] Mara Hvistendahl. Can “predictive policing” prevent crime before it happens. Science
AAAS, 2016.
[36] Matthew Joseph, Michael Kearns, Jamie H Morgenstern, and Aaron Roth. Fairness in
learning: Classic and contextual bandits. In Advances in Neural Information Processing
Systems, pages 325–333, 2016.
[37] Faisal Kamiran and Toon Calders. Classifying without discriminating. In Computer,
Control and Communication, 2009. IC4 2009. 2nd International Conference on, pages
1–6. IEEE, 2009.
[38] Faisal Kamiran and Toon Calders. Data preprocessing techniques for classification
without discrimination. Knowledge and Information Systems, 33(1):1–33, 2012.

[39] Toshihiro Kamishima, Shotaro Akaho, Hideki Asoh, and Jun Sakuma. Fairness-aware
classifier with prejudice remover regularizer. In Machine Learning and Knowledge
Discovery in Databases - European Conference, ECML PKDD 2012, Bristol, UK,
September 24-28, 2012. Proceedings, Part II, pages 35–50, 2012.
[40] Michael Kearns, Aaron Roth, and Zhiwei Steven Wu. Meritocratic fairness for crosspopulation
selection. In International Conference on Machine Learning, pages 1828–1836,
2017.
[41] Jon M. Kleinberg, Sendhil Mullainathan, and Manish Raghavan. Inherent trade-offs in
the fair determination of risk scores. In 8th Innovations in Theoretical Computer Science
Conference, ITCS 2017, January 9-11, 2017, Berkeley, CA, USA, pages 43:1–43:23,
2017.
[42] Emmanouil Krasanakis, Eleftherios Spyromitros-Xioufis, Symeon Papadopoulos, and
Yiannis Kompatsiaris. Adaptive sensitive reweighting to mitigate bias in fairness-aware
classification. In Proceedings of the 2018 World Wide Web Conference on World Wide
Web, WWW 2018, Lyon, France, April 23-27, 2018. International World Wide Web
Conferences Steering Committee, 2018.
[43] Jeff Larson, Surya Mattu, Lauren Kirchner, and Julia Angwin. How we analyzed the
compas recidivism algorithm. ProPublica (5 2016), 9, 2016.
[44] Binh Thanh Luong, Salvatore Ruggieri, and Franco Turini. k-nn as an implementation
of situation testing for discrimination discovery and prevention. In Proceedings of the
17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,
San Diego, CA, USA, August 21-24, 2011, pages 502–510. ACM, 2011.
[45] Susan Magarey. The sex discrimination act 1984. Australian Feminist Law Journal,
2004.
[46] Michael W. Mahoney, Lorenzo Orecchia, and Nisheeth K. Vishnoi. A spectral algorithm
for improving graph partitions. Journal of Machine Learning Research, 13:2339–2365,
2012.
[47] Subhransu Maji, Nisheeth K. Vishnoi, and Jitendra Malik. Biased normalized cuts. In
The 24th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2011,
Colorado Springs, CO, USA, 20-25 June 2011, pages 2057–2064, 2011.
[48] Aditya Krishna Menon and Robert C. Williamson. The cost of fairness in binary
classification. In Conference on Fairness, Accountability and Transparency, FAT 2018,
23-24 February 2018, New York, NY, USA, pages 107–118, 2018.
[49] Claire Cain Miller. Can an algorithm hire better than a human. The New York Times,
25, 2015.
[50] Harikrishna Narasimhan, Rohit Vaish, and Shivani Agarwal. On the statistical consistency
of plug-in classifiers for non-decomposable performance measures. In Advances
in Neural Information Processing Systems 27: Annual Conference on Neural Information
Processing Systems 2014, December 8-13 2014, Montreal, Quebec, Canada, pages
1493–1501, 2014.
[51] Arvind Narayanan. Tutorial: 21 fairness definitions and their politics. https://www.
youtube.com/watch?v=jIXIuYdnyyk, 2018.
[52] Northpointe. Compas risk and need assessment systems. http://www.northpointeinc.
com/files/downloads/FAQ_Document.pdf, 2012.
[53] United States. Executive Office of the President and John Podesta. Big data: Seizing
opportunities, preserving values. White House, Executive Office of the President, 2014.
[54] Dino Pedreshi, Salvatore Ruggieri, and Franco Turini. Discrimination-aware data mining.
In Proceedings of the 14th ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining, Las Vegas, Nevada, USA, August 24-27, 2008, pages
560–568. ACM, 2008.
[55] Geoff Pleiss, Manish Raghavan, Felix Wu, Jon M. Kleinberg, and Kilian Q. Weinberger.
On fairness and calibration. In Advances in Neural Information Processing Systems 30:
Annual Conference on Neural Information Processing Systems 2017, 4-9 December 2017,
Long Beach, CA, USA, pages 5684–5693, 2017.
[56] Novi Quadrianto and Viktoriia Sharmanska. Recycling privileged learning and distribution
matching for fairness. In Advances in Neural Information Processing Systems,
pages 677–688, 2017.
[57] WhiteHouse. Big data: A report on algorithmic systems, opportunity, and civil rights.
Executive Office of the President, 2016.
[58] Blake E. Woodworth, Suriya Gunasekar, Mesrob I. Ohannessian, and Nathan Srebro.
Learning non-discriminatory predictors. In Proceedings of the 30th Conference on
Learning Theory, COLT 2017, Amsterdam, The Netherlands, 7-10 July 2017, pages
1920–1953, 2017.
[59] Muhammad Bilal Zafar, Isabel Valera, Manuel Gomez-Rodriguez, and Krishna P. Gummadi.
Fairness beyond disparate treatment & disparate impact: Learning classification
without disparate mistreatment. In Proceedings of the 26th International Conference
on World Wide Web, WWW 2017, Perth, Australia, April 3-7, 2017, pages 1171–1180,
2017.
[60] Muhammad Bilal Zafar, Isabel Valera, Manuel Gomez-Rodriguez, and Krishna P.
Gummadi. Fairness constraints: Mechanisms for fair classification. In Proceedings of the
20th International Conference on Artificial Intelligence and Statistics, AISTATS 2017,
20-22 April 2017, Fort Lauderdale, FL, USA, pages 962–970, 2017.
[61] Muhammad Bilal Zafar, Isabel Valera, Manuel Gomez-Rodriguez, Krishna P. Gummadi,
and Adrian Weller. From parity to preference-based notions of fairness in classification.
In Advances in Neural Information Processing Systems 30: Annual Conference on Neural
Information Processing Systems 2017, 4-9 December 2017, Long Beach, CA, USA, pages
228–238, 2017.
[62] Rich Zemel, Yu Wu, Kevin Swersky, Toni Pitassi, and Cynthia Dwork. Learning
fair representations. In Proceedings of the 30th International Conference on Machine
Learning, ICML 2013, Atlanta, GA, USA, 16-21 June 2013, pages 325–333, 2013.
[63] Indre Zliobaite. Measuring discrimination in algorithmic decision making. Data Min.
Knowl. Discov., 2017.

# 7 Cost-Sensitive Feature Selection by Optimizing F-measures

correlation-based feature selection (CFS) 
cost-sensitive feature selection(CSFS)
Information-Theoretic Feature Ranking (ITFR)
Minimum Redundancy Maximum Relevance (mRMR)
Multi-Label ReliefF (MLReliefF)
Non-Convex Feature Learning (NCFS)
Robust Feature Selection (RFS)
support vector machine recursive feature elimination (SVM-RFE)

REFERENCES
[1] H. Lang and H. Ling, “Covert photo classification by fusing image
features and visual attributes,” IEEE Transactions on Image Processing,
vol. 24, no. 10, pp. 2996–3008, 2015.
[2] S. Bahrampour, N. M. Nasrabadi, A. Ray, and W. K. Jenkins, “Multimodal
task-driven dictionary learning for image classification,” IEEE
Transactions on Image Processing, vol. 25, no. 1, pp. 24–38, 2016.
[3] D.Wang, F. Nie, and H. Huang, “Feature selection via global redundancy
minimization,” IEEE Transactions on Knowledge & Data Engineering,
vol. PP, no. 99, pp. 2743–2755, 2015.
[4] F. Nie, S. Xiang, Y. Jia, C. Zhang, and S. Yan, “Trace ratio criterion
for feature selection,” in National Conference on Artificial Intelligence,
2008, pp. 671–676.
[5] Y. Luo, T. Liu, D. Tao, and C. Xu, “Decomposition-based transfer
distance metric learning for image classification,” IEEE Transactions
on Image Processing, vol. 23, no. 9, pp. 3789–3801, 2014.
IEEE TIP-15403-2016 FINAL VERSION, VOL. XX, NO. X, DECEMBER 2017 12
[6] M. J. Saberian and N. Vasconcelos, “Boosting algorithms for simultaneous
feature extraction and selection,” in CVPR, 2012, pp. 2448–2455.
[7] M. D. Gupta and J. Xiao, “Non-negative matrix factorization as a feature
selection tool for maximum margin classifiers,” in CVPR, 2011, pp.
2841–2848.
[8] A. Wang, J. Lu, J. Cai, G. Wang, and T.-J. Cham, “Unsupervised
joint feature learning and encoding for rgb-d scene labeling,” IEEE
Transactions on Image Processing, vol. 24, no. 11, pp. 4459–4473, 2015.
[9] Y. Yang, H. T. Shen, Z. Ma, Z. Huang, and X. Zhou, “ 2;1-norm
regularized discriminative feature selection for unsupervised learning,”
in IJCAI, 2011, pp. 1589–1594.
[10] K. Shin and A. P. Angulo, “A geometric theory of feature selection and
distance-based measures,” in IJCAI, 2015, pp. 3812–3819.
[11] S. M. Villela, S. de Castro Leite, and R. F. Neto, “Feature selection
from microarray data via an ordered search with projected margin,” in
IJCAI, 2015, pp. 3874–3881.
[12] W. Jiang, G. Er, Q. Dai, and J. Gu, “Similarity-based online feature
selection in content-based image retrieval,” IEEE Transactions on Image
Processing, vol. 15, no. 3, pp. 702–712, 2006.
[13] Y. Luo, Y. Wen, D. Tao, J. Gui, and C. Xu, “Large margin multi-modal
multi-task feature extraction for image classification,” IEEE Transactions
on Image Processing, vol. 25, no. 1, pp. 414–427, 2016.
[14] H. Tao, C. Hou, F. Nie, Y. Jiao, and D. Yi, “Effective discriminative
feature selection with nontrivial solution.” IEEE Transactions on Neural
Networks & Learning Systems, vol. 27, no. 4, pp. 3013–3017, 2016.
[15] I. Kononenko, “Estimating attributes: analysis and extensions of RELIEF,”
in ECML, 1994, pp. 171–182.
[16] H. Peng, F. Long, and C. Ding, “Feature selection based on mutual
information criteria of max-dependency, max-relevance, and minredundancy,”
IEEE Transactions on Pattern Analysis and Machine
Intelligence, vol. 27, no. 8, pp. 1226–1238, 2005.
[17] H. Liu and H. Motoda, Feature selection for knowledge discovery and
data mining. Springer Science & Business Media, 2012, vol. 454.
[18] L. E. Raileanu and K. Stoffel, “Theoretical comparison between the
gini index and information gain criteria,” Annals of Mathematics and
Artificial Intelligence, vol. 41, no. 1, pp. 77–93, 2004.
[19] M. A. Hall and L. A. Smith, “Feature selection for machine learning:
Comparing a correlation-based filter approach to the wrapper.” in
FLAIRS, 1999, pp. 235–239.
[20] I. Guyon, J. Weston, S. Barnhill, and V. Vapnik, “Gene selection for
cancer classification using support vector machines,” Machine Learning,
vol. 46, no. 1-3, pp. 389–422, 2002.
[21] F. Nie, H. Huang, X. Cai, and C. H. Ding, “Efficient and robust feature
selection via joint 2;1-norms minimization,” in NIPS, 2010, pp. 1813–
1821.
[22] D. Han and J. Kim, “Unsupervised simultaneous orthogonal basis
clustering feature selection,” in CVPR, 2015, pp. 5016–5023.
[23] J. J. Hull, “A database for handwritten text recognition research,” IEEE
Transactions on Pattern Analysis and Machine Intelligence, vol. 16,
no. 5, pp. 550–554, 1994.
[24] X. Chen and M. Wasikowski, “Fast: a roc-based feature selection metric
for small samples and imbalanced data classification problems,” in
Proceedings of the 14th ACM SIGKDD international conference on
Knowledge discovery and data mining. ACM, 2008, pp. 124–132.
[25] Q. Shi, B. Du, and L. Zhang, “Spatial coherence-based batch-mode active
learning for remote sensing image classification,” IEEE Transactions
on Image Processing, vol. 24, no. 7, pp. 2037–2050, 2015.
[26] J.-M. Guo and H. Prasetyo, “Content-based image retrieval using features
extracted from halftoning-based block truncation coding,” IEEE
Transactions on Image Processing, vol. 24, no. 3, pp. 1010–1024, 2015.
[27] Y. Chen and C. Lin, “Combining svms with various feature selection
strategies,” in Feature Extraction. Springer, 2006, pp. 315–324.
[28] M. Qian and C. Zhai, “Robust unsupervised feature selection,” in IJCAI,
2013, pp. 1621–1627.
[29] Q. Gu, Z. Li, and J. Han, “Joint feature selection and subspace learning,”
in IJCAI, 2011, pp. 1294–1299.
[30] Y. Zhang and Z.-H. Zhou, “Cost-sensitive face recognition,” IEEE
Transactions on Pattern Analysis and Machine Intelligence, vol. 32,
no. 10, pp. 1758–1769, 2010.
[31] S. P. Parambath, N. Usunier, and Y. Grandvalet, “Optimizing F-measures
by cost-sensitive classification,” in NIPS, 2014, pp. 2123–2131.
[32] K. J. Dembczynski, W. Waegeman, W. Cheng, and E. H¨ullermeier, “An
exact algorithm for F-measure maximization,” in NIPS, 2011, pp. 1404–
1412.
[33] I. Pillai, G. Fumera, and F. Roli, “F-measure optimisation in multi-label
classifiers,” in ICPR, 2012, pp. 2424–2427.
[34] W. Cheng, K. Dembczy´nski, E. H¨ullermeier, A. Jaroszewicz, and
W. Waegeman, “F-measure maximization in topical classification,” in
Rough Sets and Current Trends in Computing, 2012, pp. 439–446.
[35] K. J. Dembczynski, A. Jachnik, W. Kotlowski, W. Waegeman, and
E. H¨ullermeier, “Optimizing the F-measure in multi-label classification:
Plug-in rule approach versus structured loss minimization,” in ICML,
2013, pp. 1130–1138.
[36] N. Ye, K. M. A. Chai, W. S. Lee, and H. L. Chieu, “Optimizing Fmeasures:
a tale of two approaches,” in ICML, 2012.
[37] D. D. Lewis, “Evaluating and optimizing autonomous text classification
systems,” in SIGIR, 1995, pp. 246–254.
[38] M. Jansche, “Maximum expected F-measure training of logistic regression
models,” in Proceedings of the conference on Human Language
Technology and Empirical Methods in Natural Language Processing,
2005, pp. 692–699.
[39] I. Tsochantaridis, T. Joachims, T. Hofmann, and Y. Altun, “Large margin
methods for structured and interdependent output variables,” JMLR,
vol. 6, pp. 1453–1484, 2005.
[40] Y. Yang, “A study of thresholding strategies for text categorization,” in
SIGIR, 2001, pp. 137–145.
[41] O. O. Koyejo, N. Natarajan, P. K. Ravikumar, and I. S. Dhillon,
“Consistent binary classification with generalized performance metrics,”
in NIPS, 2014, pp. 2744–2752.
[42] H. Narasimhan, R. Vaish, and S. Agarwal, “On the statistical consistency
of plug-in classifiers for non-decomposable performance measures,” in
NIPS, 2014, pp. 1493–1501.
[43] X. Zhu, H. I. Suk, and D. Shen, “Matrix-similarity based loss function
and feature selection for Alzheimer’s disease diagnosis,” in CVPR, 2014,
pp. 3089–3096.
[44] D. Kong and C. Ding, “Non-convex feature learning via p;1 operator,”
in AAAI, 2014.
[45] M. Wasikowski and X. Chen, “Combating the small sample class imbalance
problem using feature selection,” IEEE Transactions on Knowledge
and Data Engineering, vol. 22, no. 10, pp. 1388–1400, 2010.
[46] J. Kim, Y. Wang, and Y. Yasunori, “The genia event extraction shared
task, 2013 edition-overview,” in Proceedings of the BioNLP Shared Task
2013 Workshop, 2013, pp. 8–15.
[47] S. Xiang, F. Nie, G. Meng, C. Pan, and C. Zhang, “Discriminative least
squares regression for multiclass classification and feature selection,”
IEEE Transactions on Neural Networks & Learning Systems, vol. 23,
no. 11, pp. 1738–1754, 2012.
[48] R. He, T. Tan, L. Wang, and W.-S. Zheng, “2;1 regularized correntropy
for robust feature selection,” in CVPR, 2012, pp. 2504–2511.
[49] X. Cai, F. Nie, and H. Huang, “Exact top-k feature selection via l2,
0-norm constraint.” in IJCAI, 2013, pp. 1240–1246.
[50] D. Kong, C. Ding, H. Huang, and H. Zhao, “Multi-label ReliefF and
F-statistic feature selections for image annotation,” in CVPR, 2012, pp.
2352–2359.
[51] J. Lee and D. Kim, “Fast multi-label feature selection based on
information-theoretic feature ranking,” Pattern Recognition, vol. 48,
no. 9, pp. 2761–2771, 2015.
[52] C. Elkan, “The foundations of cost-sensitive learning,” in International
joint conference on artificial intelligence, vol. 17, no. 1, 2001, pp. 973–
978.

# 8 Data Decision and Theoretical Implications when Adversarially Learning Fair Representations

ReLU
UCI

deep neural network (DNN)

REFERENCES
[1] Alex Beutel, Ed H Chi, Zhiyuan Cheng, Hubert Pham, and John Anderson. 2017.
Beyond Globally Optimal: Focused Learning for Improved Recommendations. In
Proceedings of the 26th International Conference onWorld WideWeb. International
World Wide Web Conferences Steering Commiee, 203–212.
[2] Tolga Bolukbasi, Kai-Wei Chang, James Y Zou, Venkatesh Saligrama, and Adam T
Kalai. 2016. Man is to computer programmer as woman is to homemaker? debiasing
word embeddings. In Advances in Neural Information Processing Systems.
4349–4357.
[3] Konstantinos Bousmalis, George Trigeorgis, Nathan Silberman, Dilip Krishnan,
and Dumitru Erhan. 2016. Domain separation networks. In Advances in Neural
Information Processing Systems. 343–351.
[4] John Duchi, Elad Hazan, and Yoram Singer. 2011. Adaptive subgradient methods
for online learning and stochastic optimization. Journal of Machine Learning
Research 12, Jul (2011), 2121–2159.
[5] Harrison Edwards and Amos Storkey. 2015. Censoring representations with an
adversary. arXiv preprint arXiv:1511.05897 (2015).
[6] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo
Larochelle, Franc¸ois Laviolee, Mario Marchand, and Victor Lempitsky. 2016.
Domain-adversarial training of neural networks. Journal of Machine Learning
Research 17, 59 (2016), 1–35.
[7] Moritz Hardt, Eric Price, Nati Srebro, et al. 2016. Equality of opportunity in
supervised learning. In Advances in Neural Information Processing Systems. 3315–
3323.
[8] Jon Kleinberg, Sendhil Mullainathan, and Manish Raghavan. 2016. Inherent
trade-os in the fair determination of risk scores. arXiv preprint arXiv:1609.05807
(2016).
[9] M. Lichman. 2013. UCI Machine Learning Repository. (2013). hp://archive.ics.
uci.edu/ml
[10] Christos Louizos, Kevin Swersky, Yujia Li, MaxWelling, and Richard Zemel. 2015.
e variational fair autoencoder. arXiv preprint arXiv:1511.00830 (2015).
[11] Rich Zemel, Yu Wu, Kevin Swersky, Toni Pitassi, and Cynthia Dwork. 2013.
Learning fair representations. In Proceedings of the 30th International Conference
on Machine Learning (ICML-13). 325–333.

# 9 Decision Theory for Discrimination-aware Classification

Discrimination-Aware Ensemble (DAE)
naive Bayes (NBS)
Reject Option based Classification (ROC),

REFERENCES
[1] T. Calders and S. Verwer, “Three naive Bayes approaches for
discrimination-free classification,” DMKD, vol. 21, no. 2, pp.
277–292, 2010.
[2] F. Kamiran, T. Calders, and M. Pechenizkiy, “Discrimination
aware decision tree learning,” in ICDM, 2010, pp. 869–874.
[3] D. Pedreschi, S. Ruggieri, and F. Turini, “Discriminationaware
data mining,” in KDD, 2008.
[4] B. Luong, S. Ruggieri, and F. Turini, “k-nn as an implementation
of situation testing for discrimination discovery and
prevention,” in KDD, 2011, pp. 502–510.
[5] S. Hajian and J. Domingo-Ferrer, “A methodology for direct
and indirect discrimination prevention in data mining,” TKDE,
vol. accepted, 2012.
[6] F. Kamiran and T. Calders, “Data preprocessing techniques
for classification without discrimination,” KAIS, pp. 1–33,
2012.
[7] I. Zliobaite, F. Kamiran, and T. Calders, “Handling conditional
discrimination,” in ICDM), 2011, pp. 992–1001.
[8] T. Kamishima, S. Akaho, and J. Sakuma, “Fairness-aware
learning through regularization approach,” in ICDMW), 2011.
[9] L. I. Kuncheva and C. J. Whitaker, “Measures of diversity in
classifier ensembles and their relationship with the ensemble
accuracy,” Machine Learning, vol. 51, pp. 181–207, 2003.
[10] A. Asuncion and D. Newman, “UCI machine learning repository,”
Online http://archive.ics.uci.edu/ml/, 2007.

# 10 Distillation as a Defense to Adversarial Perturbations against Deep Neural Networks

Army Research Laboratory(ARL)
Deep Learning (DL)

REFERENCES
[1] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classification
with deep convolutional neural networks,” in Advances in neural information
processing systems, 2012, pp. 1097–1105.
[2] T. N. Sainath, A.-r. Mohamed, B. Kingsbury, and B. Ramabhadran,
“Deep convolutional neural networks for lvcsr,” in Acoustics, Speech
and Signal Processing (ICASSP), 2013 IEEE International Conference
on. IEEE, 2013, pp. 8614–8618.
[3] P. Sermanet, D. Eigen, X. Zhang, M. Mathieu, R. Fergus, and Y. Le-
Cun, “Overfeat: Integrated recognition, localization and detection using
convolutional networks,” in International Conference on Learning Representations
(ICLR 2014). arXiv preprint arXiv:1312.6229, 2014.
[4] G. E. Dahl, J. W. Stokes, L. Deng, and D. Yu, “Large-scale malware
classification using random projections and neural networks,” in Acoustics,
Speech and Signal Processing (ICASSP), 2013 IEEE International
Conference on. IEEE, 2013, pp. 3422–3426.
[5] Z. Yuan, Y. Lu, Z. Wang, and Y. Xue, “Droid-sec: deep learning in
android malware detection,” in Proceedings of the 2014 ACM conference
on SIGCOMM. ACM, 2014, pp. 371–372.
[6] E. Knorr, “How paypal beats the bad guys
with machine learning,” 2015. [Online]. Available:
http://www.infoworld.com/article/2907877/machine-learning/
how-paypal-reduces-fraud-with-machine-learning.html
[7] N. Papernot, P. McDaniel, S. Jha, M. Fredrikson, Z. B. Celik, and
A. Swami, “The limitations of deep learning in adversarial settings,”
in Proceedings of the 1st IEEE European Symposium on Security and
Privacy. IEEE, 2016.
[8] C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow,
and R. Fergus, “Intriguing properties of neural networks,” in Proceedings
of the 2014 International Conference on Learning Representations.
Computational and Biological Learning Society, 2014.
[9] I. J. Goodfellow, J. Shlens, and C. Szegedy, “Explaining and harnessing
adversarial examples,” in Proceedings of the 2015 International Conference
on Learning Representations. Computational and Biological
Learning Society, 2015.
[10] NVIDIA, “Nvidia tegra drive px: Self-driving car computer,” 2015.
[Online]. Available: http://www.nvidia.com/object/drive-px.html
[11] D. Cires¸an, U. Meier, J. Masci et al., “Multi-column deep neural network
for traffic sign classification.”
[12] L. Huang, A. D. Joseph, B. Nelson, B. I. Rubinstein, and J. Tygar, “Adversarial
machine learning,” in Proceedings of the 4th ACM workshop
on Security and artificial intelligence. ACM, 2011, pp. 43–58.
[13] B. Biggio, G. Fumera et al., “Pattern recognition systems under attack:
Design issues and research challenges,” International Journal of Pattern
Recognition and Artificial Intelligence, vol. 28, no. 07, p. 1460002, 2014.
[14] B. Biggio, I. Corona, D. Maiorca, B. Nelson et al., “Evasion attacks
against machine learning at test time,” in Machine Learning and
Knowledge Discovery in Databases. Springer, 2013, pp. 387–402.
[15] A. Anjos and S. Marcel, “Counter-measures to photo attacks in face
recognition: a public database and a baseline,” in Proceedings of the
2011 International Joint Conference on Biometrics. IEEE, 2011.
[16] P. Fogla and W. Lee, “Evading network anomaly detection systems:
formal reasoning and practical techniques,” in Proceedings of the 13th
ACM conference on Computer and communications security. ACM,
2006, pp. 59–68.
[17] S. Gu and L. Rigazio, “Towards deep neural network architectures
robust to adversarial examples,” in Proceedings of the 2015 International
Conference on Learning Representations. Computational and Biological
Learning Society, 2015.
[18] J. Ba and R. Caruana, “Do deep nets really need to be deep?” in
Advances in Neural Information Processing Systems, 2014, pp. 2654–
2662.
[19] G. Hinton, O. Vinyals, and J. Dean, “Distilling the knowledge in a neural
network,” in Deep Learning and Representation Learning Workshop at
NIPS 2014. arXiv preprint arXiv:1503.02531, 2014.
[20] Y. LeCun and C. Cortes, “The mnist database of handwritten digits,”
1998.
[21] A. Krizhevsky and G. Hinton, “Learning multiple layers of features from
tiny images,” 2009.
[22] Y. Bengio, I. J. Goodfellow, and A. Courville, “Deep learning,”
2015, book in preparation for MIT Press. [Online]. Available:
http://www.iro.umontreal.ca/bengioy/dlbook
[23] G. E. Hinton, “Learning multiple layers of representation,” Trends in
cognitive sciences, vol. 11, no. 10, pp. 428–434, 2007.
[24] D. E. Rumelhart, G. E. Hinton, and R. J. Williams, “Learning representations
by back-propagating errors,” Cognitive modeling, vol. 5, 1988.
[25] J. Bergstra and Y. Bengio, “Random search for hyper-parameter optimization,”
The Journal of Machine Learning Research, vol. 13, no. 1,
pp. 281–305, 2012.
[26] X. Glorot, A. Bordes, and Y. Bengio, “Domain adaptation for largescale
sentiment classification: A deep learning approach,” in Proceedings
of the 28th International Conference on Machine Learning (ICML-11),
2011, pp. 513–520.
[27] J. Masci, U. Meier, D. Cires¸an et al., “Stacked convolutional autoencoders
for hierarchical feature extraction,” in Artificial Neural Networks
and Machine Learning–ICANN 2011. Springer, 2011, pp. 52–59.
[28] D. Erhan, Y. Bengio, A. Courville, P.-A. Manzagol, P. Vincent, and
S. Bengio, “Why does unsupervised pre-training help deep learning?”
The Journal of Machine Learning Research, vol. 11, pp. 625–660, 2010.
[29] T. Miyato, S. Maeda, M. Koyama et al., “Distributional smoothing by
virtual adversarial examples,” CoRR, vol. abs/1507.00677, 2015.
[30] A. Fawzi, O. Fawzi, and P. Frossard, “Analysis of classifiers’ robustness
to adversarial perturbations,” in Deep Learning Workshop at ICML 2015.
arXiv preprint arXiv:1502.02590, 2015.
[31] H. Drucker and Y. Le Cun, “Improving generalization performance
using double backpropagation,” Neural Networks, IEEE Transactions
on, vol. 3, no. 6, pp. 991–997, 1992.
[32] A. Nguyen, J. Yosinski, and J. Clune, “Deep neural networks are easily
fooled: High confidence predictions for unrecognizable images,” in In
Computer Vision and Pattern Recognition (CVPR 2015). IEEE, 2015.
[33] G. Cybenko, “Approximation by superpositions of a sigmoidal function,”
Mathematics of Control, Signals, and Systems , vol. 5, no. 4, p. 455,
1992.
[34] S. Shalev-Shwartz, O. Shamir, N. Srebro, and K. Sridharan, “Learnability,
stability and uniform convergence,” The Journal of Machine
Learning Research, vol. 11, pp. 2635–2670, 2010.
[35] J. Bergstra, O. Breuleux, F. Bastien, P. Lamblin, R. Pascanu, G. Desjardins,
J. Turian, D. Warde-Farley, and Y. Bengio, “Theano: a cpu
and gpu math expression compiler,” in Proceedings of the Python for
scientific computing conference (SciPy), vol. 4. Austin, TX, 2010, p. 3.
[36] E. Battenberg, S. Dieleman, D. Nouri, E. Olson, A. van den Oord,
C. Raffel, J. Schlter, and S. Kaae Snderby, “Lasagne: Lightweight
library to build and train neural networks in theano,” 2015. [Online].
Available: https://github.com/Lasagne/Lasagne
[37] B. Biggio, K. Rieck, D. Ariu, C. Wressnegger et al., “Poisoning
behavioral malware clustering,” in Proceedings of the 2014 Workshop
on Artificial Intelligent and Security Workshop. ACM, 2014, pp. 27–36.
[38] D. Warde-Farley and I. Goodfellow, “Adversarial perturbations of deep
neural networks,” in Advanced Structured Prediction, T. Hazan, G. Papandreou,
and D. Tarlow, Eds., 2016.
[39] M. Barreno, B. Nelson, A. D. Joseph, and J. Tygar, “The security of
machine learning,” Machine Learning, vol. 81, no. 2, pp. 121–148, 2010.
[40] W. Xu, Y. Qi et al., “Automatically evading classifiers,” in Proceedings
of the 2016 Network and Distributed Systems Symposium, 2016.
[41] M. Barreno, B. Nelson, R. Sears, A. D. Joseph, and J. D. Tygar,
“Can machine learning be secure?” in Proceedings of the 2006 ACM
Symposium on Information, computer and communications security.
ACM, 2006, pp. 16–25.
[42] B. Biggio, G. Fumera, and F. Roli, “Security evaluation of pattern
classifiers under attack,” Knowledge and Data Engineering, IEEE Transactions
on, vol. 26, no. 4, pp. 984–996, 2014.
[43] B. Biggio, B. Nelson, and L. Pavel, “Poisoning attacks against support
vector machines,” in Proceedings of the 29th International Conference
on Machine Learning, 2012.
[44] B. Biggio, B. Nelson, and P. Laskov, “Support vector machines under
adversarial label noise.” in ACML, 2011, pp. 97–112.

 # 11 Domain-Adversarial Training of Neural Networks
 
 CMC
 PRID
 CUHK
 
 Canada Foundation for Innovation (CFI)
 
 domain adaptation (DA)
 
 Deep Metric Learning (DM)
 
 Fonds de recherche du Quebec Nature et technologies (FRQNT)
 
 gradient reversal layer (GRL)
 
 marginalized Stacked Autoencoders (mSDA)
 
 National Science and Engineering Research Council (NSERC)
 
 Proxy A-distances (PAD)
 
 References
 
Hana Ajakan, Pascal Germain, Hugo Larochelle, Francois Laviolette, and Mario Marchand.
Domain-adversarial neural networks. NIPS 2014 Workshop on Transfer and Multi-task
learning: Theory Meets Practice, 2014. URL http://arxiv.org/abs/1412.4446.
Pablo Arbelaez, Michael Maire, Charless Fowlkes, and Jitendra Malik. Contour detection
and hierarchical image segmentation. IEEE Transaction Pattern Analysis and Machine
Intelligence, 33, 2011.
Artem Babenko, Anton Slesarev, Alexander Chigorin, and Victor S. Lempitsky. Neural
codes for image retrieval. In ECCV, pages 584{599, 2014.
Mahsa Baktashmotlagh, Mehrtash Tafazzoli Harandi, Brian C. Lovell, and Mathieu Salzmann.
Unsupervised domain adaptation by domain invariant projection. In ICCV, pages
769{776, 2013.
Shai Ben-David, John Blitzer, Koby Crammer, and Fernando Pereira. Analysis of representations
for domain adaptation. In NIPS, pages 137{144, 2006.
Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer
Wortman Vaughan. A theory of learning from dierent domains. Machine Learning,
79(1-2):151{175, 2010.
John Blitzer, Ryan T. McDonald, and Fernando Pereira. Domain adaptation with structural
correspondence learning. In Conference on Empirical Methods in Natural Language
Processing, pages 120{128, 2006.

Ganin, Ustinova, Ajakan, Germain, Larochelle, Laviolette, Marchand and Lempitsky
Karsten M. Borgwardt, Arthur Gretton, Malte J. Rasch, Hans-Peter Kriegel, Bernhard
Scholkopf, and Alexander J. Smola. Integrating structured biological data by kernel
maximum mean discrepancy. In ISMB, pages 49{57, 2006.
Lorenzo Bruzzone and Mattia Marconcini. Domain adaptation problems: A DASVM classi-
cation technique and a circular validation strategy. IEEE Transaction Pattern Analysis
and Machine Intelligence, 32(5):770{787, 2010.
Minmin Chen, Zhixiang Eddie Xu, Kilian Q. Weinberger, and Fei Sha. Marginalized denoising
autoencoders for domain adaptation. In ICML, pages 767{774, 2012.
Qiang Chen, Junshi Huang, Rogerio Feris, Lisa M. Brown, Jian Dong, and Shuicheng Yan.
Deep domain adaptation for describing people based on ne-grained clothing attributes.
In CVPR, June 2015.
S. Chopra, S. Balakrishnan, and R. Gopalan. Dlid: Deep learning for domain adaptation
by interpolating between domains. In ICML Workshop on Challenges in Representation
Learning, 2013.
Dan Ciresan, Ueli Meier, Jonathan Masci, and Jurgen Schmidhuber. Multi-column deep
neural network for trac sign classication. Neural Networks, 32:333{338, 2012.
Corinna Cortes and Mehryar Mohri. Domain adaptation and sample bias correction theory
and algorithm for regression. Theor. Comput. Sci., 519:103{126, 2014.
Je Donahue, Yangqing Jia, Oriol Vinyals, Judy Homan, Ning Zhang, Eric Tzeng, and
Trevor Darrell. Decaf: A deep convolutional activation feature for generic visual recognition.
In ICML, 2014.
John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online
learning and stochastic optimization. Technical report, EECS Department, University of
California, Berkeley, Mar 2010.
Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin. LIBLINEAR:
A library for large linear classication. Journal of Machine Learning Research,
9:1871{1874, 2008.
Basura Fernando, Amaury Habrard, Marc Sebban, and Tinne Tuytelaars. Unsupervised
visual domain adaptation using subspace alignment. In ICCV, 2013.
Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by backpropagation.
In ICML, pages 325{333, 2015. URL http://jmlr.org/proceedings/papers/
v37/ganin15.html.
Pascal Germain, Amaury Habrard, Francois Laviolette, and Emilie Morvant. A PACBayesian
approach for domain adaptation with specialization to linear classiers. In
ICML, pages 738{746, 2013.
Xavier Glorot, Antoine Bordes, and Yoshua Bengio. Domain adaptation for large-scale
sentiment classication: A deep learning approach. In ICML, pages 513{520, 2011.

Domain-Adversarial Neural Networks
Boqing Gong, Yuan Shi, Fei Sha, and Kristen Grauman. Geodesic 
ow kernel for unsupervised
domain adaptation. In CVPR, pages 2066{2073, 2012.
Boqing Gong, Kristen Grauman, and Fei Sha. Connecting the dots with landmarks: Discriminatively
learning domain-invariant features for unsupervised domain adaptation. In
ICML, pages 222{230, 2013.
Shaogang Gong, Marco Cristani, Shuicheng Yan, and Chen Change Loy. Person re-
identication. Springer, 2014.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil
Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In NIPS, 2014.
Raghuraman Gopalan, Ruonan Li, and Rama Chellappa. Domain adaptation for object
recognition: An unsupervised approach. In ICCV, pages 999{1006, 2011.
Doug Gray, Shane Brennan, and Hai Tao. Evaluating appearance models for recognition,
reacquisition, and tracking. In IEEE International Workshop on Performance Evaluation
for Tracking and Surveillance, Rio de Janeiro, 2007.
Martin Hirzer, Csaba Beleznai, Peter M. Roth, and Horst Bischof. Person re-identication
by descriptive and discriminative classication. In SCIA, 2011.
Judy Homan, Eric Tzeng, Je Donahue, Yangqing Jia, Kate Saenko, and Trevor Darrell.
One-shot adaptation of supervised deep convolutional models. CoRR, abs/1312.6204,
2013. URL http://arxiv.org/abs/1312.6204.
Fei Huang and Alexander Yates. Biased representation learning for domain adaptation. In
Joint Conference on Empirical Methods in Natural Language Processing and Computa-
tional Natural Language Learning, pages 1313{1323, 2012.
Jiayuan Huang, Alexander J. Smola, Arthur Gretton, Karsten M. Borgwardt, and Bernhard
Scholkopf. Correcting sample selection bias by unlabeled data. In NIPS, pages 601{608,
2006.
Yangqing Jia, Evan Shelhamer, Je Donahue, Sergey Karayev, Jonathan Long, Ross Girshick,
Sergio Guadarrama, and Trevor Darrell. Cae: Convolutional architecture for fast
feature embedding. CoRR, abs/1408.5093, 2014.
Daniel Kifer, Shai Ben-David, and Johannes Gehrke. Detecting change in data streams. In
Very Large Data Bases, pages 180{191, 2004.
Alex Krizhevsky, Ilya Sutskever, and Georey Hinton. Imagenet classication with deep
convolutional neural networks. In NIPS, pages 1097{1105, 2012.
Alexandre Lacoste, Francois Laviolette, and Mario Marchand. Bayesian comparison of
machine learning algorithms on single and multiple datasets. In AISTATS, pages 665{
675, 2012.
Y. LeCun, L. Bottou, Y. Bengio, and P. Haner. Gradient-based learning applied to document
recognition. Proceedings of the IEEE, 86(11):2278{2324, November 1998.

Ganin, Ustinova, Ajakan, Germain, Larochelle, Laviolette, Marchand and Lempitsky
Wei Li and Xiaogang Wang. Locally aligned feature transforms across views. In CVPR,
pages 3594{3601, 2013.
Yujia Li, Kevin Swersky, and Richard Zemel. Unsupervised domain adaptation by domain
invariant projection. In NIPS 2014 Workshop on Transfer and Multitask Learning, 2014.
Joerg Liebelt and Cordelia Schmid. Multi-view object class detection with a 3d geometric
model. In CVPR, 2010.
Chunxiao Liu, Chen Change Loy, Shaogang Gong, and Guijin Wang. POP: person reidenti
cation post-rank optimisation. In ICCV, pages 441{448, 2013.
Mingsheng Long and Jianmin Wang. Learning transferable features with deep adaptation
networks. CoRR, abs/1502.02791, 2015.
Andy Jinhua Ma, Jiawei Li, Pong C. Yuen, and Ping Li. Cross-domain person reidenti-
cation using domain adaptation ranking svms. IEEE Transactions on Image Processing,
24(5):1599{1613, 2015.
Yishay Mansour, Mehryar Mohri, and Afshin Rostamizadeh. Domain adaptation: Learning
bounds and algorithms. In COLT, 2009a.
Yishay Mansour, Mehryar Mohri, and Afshin Rostamizadeh. Multiple source adaptation
and the renyi divergence. In UAI, pages 367{374, 2009b.
Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y. Ng.
Reading digits in natural images with unsupervised feature learning. In NIPS Workshop
on Deep Learning and Unsupervised Feature Learning, 2011.
M. Oquab, L. Bottou, I. Laptev, and J. Sivic. Learning and transferring mid-level image
representations using convolutional neural networks. In CVPR, 2014.
Sakrapee Paisitkriangkrai, Chunhua Shen, and Anton van den Hengel. Learning to rank
in person re-identication with metric ensembles. CoRR, abs/1503.01543, 2015. URL
http://arxiv.org/abs/1503.01543.
Sinno Jialin Pan, Ivor W. Tsang, James T. Kwok, and Qiang Yang. Domain adaptation
via transfer component analysis. IEEE Transactions on Neural Networks, 22(2):199{210,
2011.
Kate Saenko, Brian Kulis, Mario Fritz, and Trevor Darrell. Adapting visual category models
to new domains. In ECCV, pages 213{226, 2010.
Nitish Srivastava, Georey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov.
Dropout: A simple way to prevent neural networks from overtting. The Journal
of Machine Learning Research, 15(1):1929{1958, 2014.
Michael Stark, Michael Goesele, and Bernt Schiele. Back to the future: Learning shape
models from 3d CAD data. In BMVC, pages 1{11, 2010.

Domain-Adversarial Neural Networks
Baochen Sun and Kate Saenko. From virtual to reality: Fast adaptation of virtual object
detectors to real domains. In BMVC, 2014.
Eric Tzeng, Judy Homan, Ning Zhang, Kate Saenko, and Trevor Darrell. Deep domain
confusion: Maximizing for domain invariance. CoRR, abs/1412.3474, 2014. URL http:
//arxiv.org/abs/1412.3474.
Laurens van der Maaten. Barnes-Hut-SNE. CoRR, abs/1301.3342, 2013. URL http:
//arxiv.org/abs/1301.3342.
David Vazquez, Antonio Manuel Lopez, Javier Marn, Daniel Ponsa, and David Geronimo
Gomez. Virtual and real world adaptationfor pedestrian detection. IEEE Transaction
Pattern Analysis and Machine Intelligence, 36(4):797{809, 2014.
Pascal Vincent, Hugo Larochelle, Yoshua Bengio, and Pierre-Antoine Manzagol. Extracting
and composing robust features with denoising autoencoders. In ICML, pages 1096{1103,
2008.
Dong Yi, Zhen Lei, and Stan Z. Li. Deep metric learning for practical person reidenti
cation. CoRR, abs/1407.4979, 2014. URL http://arxiv.org/abs/1407.4979.
Matthew D. Zeiler. ADADELTA: an adaptive learning rate method. CoRR, abs/1212.5701,
2012. URL http://arxiv.org/abs/1212.5701.
Matthew D. Zeiler and Rob Fergus. Visualizing and understanding convolutional networks.
CoRR, abs/1311.2901, 2013. URL http://arxiv.org/abs/1311.2901.
Ziming Zhang and Venkatesh Saligrama. Person re-identication via structured prediction.
CoRR, abs/1406.4444, 2014. URL http://arxiv.org/abs/1406.4444.
Rui Zhao, Wanli Ouyang, and XiaogangWang. Person re-identication by saliency learning.
CoRR, abs/1412.1908, 2014. URL http://arxiv.org/abs/1412.1908.
Erheng Zhong, Wei Fan, Qiang Yang, Olivier Verscheure, and Jiangtao Ren. Cross validation
framework to choose amongst models and datasets for transfer learning. In Machine
Learning and Knowledge Discovery in Databases, pages 547{562. Springer, 2010.

# 12  Empirical Risk Minimization under Fairness Constraints

ERM

FERM

ACC

Equal Opportunity (EO)

Reproducing Kernel Hilbert Space (RKHS)


References
[1] C. Dwork, N. Immorlica, A. T. Kalai, and M. D. M. Leiserson. Decoupled classifiers for group-fair and
efficient machine learning. In Conference on Fairness, Accountability and Transparency, 2018.
[2] M. Hardt, E. Price, and N. Srebro. Equality of opportunity in supervised learning. In Advances in neural
information processing systems, 2016.
[3] M. B. Zafar, I. Valera, M. Gomez Rodriguez, and K. P. Gummadi. Fairness beyond disparate treatment &
disparate impact: Learning classification without disparate mistreatment. In International Conference on
World Wide Web, 2017.
[4] R. Zemel, Y. Wu, K. Swersky, T. Pitassi, and C. Dwork. Learning fair representations. In International
Conference on Machine Learning, 2013.
[5] N. Kilbertus, M. Rojas-Carulla, G. Parascandolo, M. Hardt, D. Janzing, and B. Schölkopf. Avoiding
discrimination through causal reasoning. In Advances in Neural Information Processing Systems, 2017.
[6] M. J. Kusner, J. Loftus, C. Russell, and R. Silva. Counterfactual fairness. In Advances in Neural Information
Processing Systems, 2017.
[7] F. Calmon, D. Wei, B. Vinzamuri, K. Natesan Ramamurthy, and K. R. Varshney. Optimized preprocessing
for discrimination prevention. In Advances in Neural Information Processing Systems, 2017.
[8] M. Joseph, M. Kearns, J. H. Morgenstern, and A. Roth. Fairness in learning: Classic and contextual
bandits. In Advances in Neural Information Processing Systems, 2016.
[9] F. Chierichetti, R. Kumar, S. Lattanzi, and S. Vassilvitskii. Fair clustering through fairlets. In Advances
in Neural Information Processing Systems, 2017.
[10] S. Jabbari, M. Joseph, M. Kearns, J. Morgenstern, and A. Roth. Fair learning in markovian environments.
In Conference on Fairness, Accountability, and Transparency in Machine Learning, 2016.
[11] S. Yao and B. Huang. Beyond parity: Fairness objectives for collaborative filtering. In Advances in Neural
Information Processing Systems, 2017.
[12] K. Lum and J. Johndrow. A statistical framework for fair predictive algorithms. arXiv preprint
arXiv:1610.08077, 2016.
[13] I. Zliobaite. On the relation between accuracy and fairness in binary classification. arXiv preprint
arXiv:1505.05723, 2015.
[14] T. Calders, F. Kamiran, and M. Pechenizkiy. Building classifiers with independency constraints. In IEEE
international conference on Data mining, 2009.
[15] G. Pleiss, M. Raghavan, F. Wu, J. Kleinberg, and K. Q. Weinberger. On fairness and calibration. In
Advances in Neural Information Processing Systems, 2017.
[16] A. Beutel, J. Chen, Z. Zhao, and E. H. Chi. Data decisions and theoretical implications when adversarially
learning fair representations. In Conference on Fairness, Accountability, and Transparency in Machine
Learning, 2017.
9
[17] M. Feldman, S. A. Friedler, J. Moeller, C. Scheidegger, and S. Venkatasubramanian. Certifying and
removing disparate impact. In International Conference on Knowledge Discovery and Data Mining,
2015.
[18] A. Agarwal, A. Beygelzimer, M. Dudík, and J. Langford. A reductions approach to fair classification. In
Conference on Fairness, Accountability, and Transparency in Machine Learning, 2017.
[19] A. Agarwal, A. Beygelzimer, M. Dudík, J. Langford, and H. Wallach. A reductions approach to fair
classification. arXiv preprint arXiv:1803.02453, 2018.
[20] B.Woodworth, S. Gunasekar, M. I. Ohannessian, and N. Srebro. Learning non-discriminatory predictors.
In Computational Learning Theory, 2017.
[21] A. K. Menon and R. C. Williamson. The cost of fairness in binary classification. In Conference on
Fairness, Accountability and Transparency, 2018.
[22] M. B. Zafar, I. Valera, M. Rodriguez, K. Gummadi, and A. Weller. From parity to preference-based
notions of fairness in classification. In Advances in Neural Information Processing Systems, 2017.
[23] Y. Bechavod and K. Ligett. Penalizing unfairness in binary classification. arXiv preprint
arXiv:1707.00044v3, 2018.
[24] M. B. Zafar, I. Valera, M. Gomez Rodriguez, and K. P. Gummadi. Fairness constraints: Mechanisms for
fair classification. In International Conference on Artificial Intelligence and Statistics, 2017.
[25] T. Kamishima, S. Akaho, and J. Sakuma. Fairness-aware learning through regularization approach. In
International Conference on Data Mining Workshops, 2011.
[26] M. Kearns, S. Neel, A. Roth, and Z. S. Wu. Preventing fairness gerrymandering: Auditing and learning
for subgroup fairness. arXiv preprint arXiv:1711.05144, 2017.
[27] A. Pérez-Suay, V. Laparra, G. Mateo-García, J. Muñoz-Marí, L. Gómez-Chova, and G. Camps-Valls. Fair
kernel learning. In Machine Learning and Knowledge Discovery in Databases, 2017.
[28] R. Berk, H. Heidari, S. Jabbari, M. Joseph, M. Kearns, J. Morgenstern, S. Neel, and A. Roth. A convex
framework for fair regression. arXiv preprint arXiv:1706.02409, 2017.
[29] D. Alabi, N. Immorlica, and A. T. Kalai. When optimizing nonlinear objectives is no harder than linear
objectives. arXiv preprint arXiv:1804.04503, 2018.
[30] M. Olfat and A. Aswani. Spectral algorithms for computing fair support vector machines. In International
Conference on Artificial Intelligence and Statistics, 2018.
[31] J. Adebayo and L. Kagal. Iterative orthogonal feature projection for diagnosing bias in black-box models.
In Conference on Fairness, Accountability, and Transparency in Machine Learning, 2016.
[32] F. Kamiran and T. Calders. Classifying without discriminating. In International Conference on Computer,
Control and Communication, 2009.
[33] F. Kamiran and T. Calders. Data preprocessing techniques for classification without discrimination.
Knowledge and Information Systems, 33(1):1–33, 2012.
[34] F. Kamiran and T. Calders. Classification with no discrimination by preferential sampling. In Machine
Learning Conference, 2010.
[35] S. Shalev-Shwartz and S. Ben-David. Understanding machine learning: From theory to algorithms.
Cambridge University Press, 2014.
[36] P. L. Bartlett and S. Mendelson. Rademacher and gaussian complexities: Risk bounds and structural
results. Journal of Machine Learning Research, 3(Nov):463–482, 2002.
[37] A. Maurer. A note on the pac bayesian theorem. arXiv preprint cs/0411099, 2004.
[38] J. Shawe-Taylor and N. Cristianini. Kernel methods for pattern analysis. Cambridge University Press,
2004.
[39] A. J. Smola and B. Schölkopf. Learning with Kernels. MIT Press, 2001.
[40] B. Schölkopf, R. Herbrich, and A. Smola. A generalized representer theorem. In Computational Learning
Theory, 2001.
[41] V. N. Vapnik. Statistical learning theory. Wiley New York, 1998.
[42] R. T. Rockafellar. Convex Analysis. Princeton University Press, 1970.

# 13 Enhancing the Accuracy and Fairness of Human Decision Making



References
[1] S. Barocas and A. D. Selbst. Big data´s disparate impact. California Law Review, 2016.
[2] S. Boyd and L. Vandenberghe. Convex optimization. Cambridge university press, 2004.
[3] S. Corbett-Davies, E. Pierson, A. Feller, S. Goel, and A. Huq. Algorithmic decision making
and the cost of fairness. KDD, 2017.
[4] C. Dwork, M. Hardt, T. Pitassi, O. Reingold, and R. Zemel. Fairness through awareness.
In ITCS, 2012.
[5] M. Feldman, S. A. Friedler, J. Moeller, C. Scheidegger, and S. Venkatasubramanian. Certifying
and removing disparate impact. In KDD, 2015.
[6] M. Hardt, E. Price, N. Srebro, et al. Equality of opportunity in supervised learning. In
NIPS, 2016.
[7] J. Kleinberg, H. Lakkaraju, J. Leskovec, J. Ludwig, and S. Mullainathan. Human decisions
and machine predictions. The Quarterly Journal of Economics, 133(1):237–293, 2017.
[8] J. Larson, S. Mattu, L. Kirchner, and J. Angwin.
https://github.com/propublica/compas-analysis, 2016.
[9] M. Mastrolilli and G. Stamoulis. Constrained matching problems in bipartite graphs. In
ISCO, pages 344–355. Springer, 2012.
[10] C. Mu˜noz, M. Smith, and D. Patil. Big Data: A Report on Algorithmic Systems, Opportunity,
and Civil Rights. Executive Office of the President. The White House., 2016.

[11] I. Osband, D. Russo, and B. Van Roy. (more) efficient reinforcement learning via posterior
sampling. In NIPS, pages 3003–3011, 2013.
[12] D. B. West et al. Introduction to graph theory, volume 2. Prentice hall Upper Saddle River,
2001.
[13] B. Zafar, I. Valera, M. Gomez-Rodriguez, and K. Gummadi. Fairness beyond disparate
treatment & disparate impact: Learning classification without disparate mistreatment. In
WWW, 2017.
[14] B. Zafar, I. Valera, M. Gomez-Rodriguez, and K. Gummadi. Training fair classifiers. AIS-
TATS, 2017.
[15] B. Zafar, I. Valera, M. Gomez-Rodriguez, K. Gummadi, and A. Weller. From parity to
preference: Learning with cost-effective notions of fairness. In NIPS, 2017.

 # 14 Evolution of collective fairness in hybrid populations of humans and agents
 
 MIT
 USD
 
Amazon Mechanical Turk (AMT) 

Evolutionary Game Theory (EGT)
 
Multiplayer version of the Ultimatum Game (MUG)

Ultimatum Game (UG) 

References
Azaria, A.; Aumann, Y.; and Kraus, S. 2012. Automated
strategies for determining rewards for human work. In
AAAI-12, 1514–1521. AAAI Press.
Blount, S. 1995. When social outcomes aren’t fair: The
effect of causal attributions on preferences. Organ. Behav.
Hum. Decis. Process 63(2):131–144.
Brˆanzei, S.; Caragiannis, I.; Kurokawa, D.; and Procaccia,
A. D. 2016. An algorithmic framework for strategic fair
division. In AAAI-16, 418–424. AAAI Press.
Camerer, C. 2003. Behavioral game theory: Experiments in
strategic interaction. Princeton University Press.
Chen, Y.; Lai, J. K.; Parkes, D. C.; and Procaccia, A. D.
2010. Truth, justice, and cake cutting. In AAAI-10, 756–
761. AAAI Press.
Chevaleyre, Y.; Dunne, P. E.; Endriss, U.; Lang, J.; Lemaitre,
M.; Maudet, N.; Padget, J.; Phelps, S.; Rodriguez-Aguilar,
J. A.; and Sousa, P. 2006. Issues in multiagent resource
allocation. Informatica 3–31.
Chica, M.; Chiong, R.; Kirley, M.; and Ishibuchi, H. 2017.
A networked n-player trust game and its evolutionary dynamics.
IEEE Trans. Evol. Comput.
Chiong, R., and Kirley, M. 2012. Effects of iterated interactions
in multiplayer spatial evolutionary games. IEEE Trans.
Evol. Comput. 16(4):537–555.
Correia, F.; Mascarenhas, S.; Prada, R.; Melo, F. S.; and
Paiva, A. 2018. Group-based emotions in teams of humans
and robots. In HRI-18, 261–269. ACM.
de Jong, S., and Tuyls, K. 2011. Human-inspired computational
fairness. Auton. Agents. Multi. Agent. Syst. 22(1):103.
de Jong, S.; Uyttendaele, S.; and Tuyls, K. 2008. Learning
to reach agreement in a continuous ultimatum game. J. Artif.
Intell. Res. 33:551–574.
de Melo, C. M.; Marsella, S.; and Gratch, J. 2018. Social
decisions and fairness change when people’s interests are
represented by autonomous agents. Auton. Agents. Multi.
Agent. Syst. 32(1):163–187.
Fehr, E., and Fischbacher, U. 2003. The nature of human
altruism. Nature 425(6960):785.
Grimm, V.; Feicht, R.; Rau, H.; and Stephan, G. 2017. On
the impact of quotas and decision rules in ultimatum collective
bargaining. Eur. Econ. Rev. 100:175–192.
G¨uth, W.; Schmittberger, R.; and Schwarze, B. 1982. An
experimental analysis of ultimatum bargaining. J. Econ. Behav.
Organ. 3(4):367–388.
Han, T.; Pereira, L. M.; Martinez-Vaquero, L. A.; and
Lenaerts, T. 2017. Centralized vs. personalized commitments
and their influence on cooperation in group interactions.
In AAAI-17, 2999–3005. AAAI Press.
Han, T. A.; Pereira, L. M.; and Lenaerts, T. 2017. Evolution
of commitment and level of participation in public goods
games. Auton. Agents. Multi. Agent. Syst. 31(3):561–583.
Jennings, N. R.; Faratin, P.; Lomuscio, A. R.; Parsons, S.;
Wooldridge, M. J.; and Sierra, C. 2001. Automated negotiation:
prospects, methods and challenges. Group. Decis.
Negot. 10(2):199–215.
Mason, W., and Suri, S. 2012. Conducting behavioral research
on amazon’s mechanical turk. Behav. Res. Methods.
44(1):1–23.
Morales, J.; Wooldridge, M.; Rodr´ıguez-Aguilar, J. A.; and
L´opez-S´anchez, M. 2018. Off-line synthesis of evolutionarily
stable normative systems. Auton. Agents. Multi. Agent.
Syst. 1–37.
Nowak, M. A.; Page, K. M.; and Sigmund, K. 2000.
Fairness versus reason in the ultimatum game. Science
289(5485):1773–1775.
Osborne, M. J. 2004. An introduction to game theory. Oxford
University Press New York.
Page, K. M.; Nowak, M. A.; and Sigmund, K. 2000. The
spatial ultimatum game. Proc. R. Soc. Lond. B Biol. Sci.
267(1458):2177–2182.
Paiva, A.; Santos, F. P.; and Santos, F. C. 2018. Engineering
pro-sociality with autonomous agents. In AAAI-18, 7994–
7999. AAAI Press.
Parkes, D. C., and Wellman, M. P. 2015. Economic reasoning
and artificial intelligence. Science 349(6245):267–272.
Rosenfeld, A., and Kraus, S. 2015. Providing arguments in
discussions based on the prediction of human argumentative
behavior. In AAAI-15, 1320–1327. AAAI Press.
Sanfey, A. G.; Rilling, J. K.; Aronson, J. A.; Nystrom,
L. E.; and Cohen, J. D. 2003. The neural basis of economic
decision-making in the ultimatum game. Science
300(5626):1755–1758.
Santos, F. P.; Santos, F. C.; Paiva, A.; and Pacheco, J. M.
2015. Evolutionary dynamics of group fairness. J. Theor.
Biol. 378:96–102.
Santos, F. P.; Santos, F. C.; Melo, F. S.; Paiva, A.; and
Pacheco, J. M. 2016. Dynamics of fairness in groups of
autonomous learning agents. In AAMAS 2016, Workshops
Best Papers, 107–126. Springer, Cham.
Santos, F. P.; Pacheco, J. M.; and Santos, F. C. 2018. Social
norms of cooperation with costly reputation building. In
AAAI-18, 4727–4734. AAAI Press.
Segal-Halevi, E.; Hassidim, A.; and Aumann, Y. 2015.
Envy-free cake-cutting in two dimensions. In AAAI-15,
1021–1028. AAAI Press.
Shirado, H., and Christakis, N. A. 2017. Locally noisy autonomous
agents improve global human coordination in network
experiments. Nature 545(7654):370.
Takesue, H.; Ozawa, A.; and Morikawa, S. 2017. Evolution
of favoritism and group fairness in a co-evolving threeperson
ultimatum game. EPL 118(4):48002.
Traulsen, A.; Nowak, M. A.; and Pacheco, J. M. 2006.
Stochastic dynamics of invasion and fixation. Phys. Rev. E
74(1):011909.
Van Segbroeck, S.; Pacheco, J. M.; Lenaerts, T.; and Santos,
F. C. 2012. Emergence of fairness in repeated group
interactions. Phys. Rev. Lett. 108(15):158104.
Weibull, J. W. 1997. Evolutionary game theory. MIT press.
